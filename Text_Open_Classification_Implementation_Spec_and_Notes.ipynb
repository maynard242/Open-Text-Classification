{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Plan and Steps\n",
    "\n",
    "** Due Dates:**\n",
    "\n",
    "* Presentation (**Dec 15th - 19th**)\n",
    "* Report (**Dec 19th**)\n",
    "\n",
    "\n",
    "### 1. Implementation \n",
    "\n",
    "#### Paragraph to Vec (target: Nov 26th)\n",
    "\n",
    "* Finalize and its output need to align with the dimension of CNN output\n",
    "\n",
    "#### Word Embedding\n",
    "\n",
    "* Pretrained google word2vec\n",
    "\n",
    "* Not trained word embedding to be trained with CNN\n",
    "\n",
    "#### CNN (need to follow the paper)\n",
    "\n",
    "* Paper has a unique 2 hidden layer structure CNN output, we will just use a softmax output layer\n",
    "\n",
    "* Region sizes, filter size, width size to mirror the paper\n",
    "\n",
    "#### Open Classification\n",
    "\n",
    "* 1-vs-Rest\n",
    "\n",
    "* Clustering approach\n",
    "    * Gaussian Mixture Model\n",
    "    * Infinite Dirichlet process\n",
    "\n",
    "### 2. Training and Cross Validation\n",
    "\n",
    "#### Full combinations: can start in pipeline or parallel once the implementation is ready\n",
    "\n",
    "* paragraph vec + 1-vs-rest\n",
    "* paragraph vec + GM\n",
    "* paragraph vec + IDPs\n",
    "* CNN + 1-vs-rest\n",
    "* CNN + GM\n",
    "* CNN + IDP\n",
    "\n",
    "### 3. Experiment Evaluation\n",
    "\n",
    "* Use Macro F1 Score\n",
    "\n",
    "### 4. Report write-up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph Vector Model\n",
    "\n",
    "#### Ref: (Le and Mikolov, 2014) https://arxiv.org/pdf/1405.4053v2.pdf)\n",
    "\n",
    "* Max vocab size = 20000\n",
    "* Output feature vector size = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN (Converlutional Neural Network)\n",
    "\n",
    "#### Ref:\n",
    "\n",
    "**Model Structure and Parameters:**\n",
    "\n",
    "* Embedding Layer:\n",
    "\n",
    "    * batch_size: N\n",
    "    * number of class: M\n",
    "    * word embedding dimension: d = 300\n",
    "    * Sentence length: s = 500 (meidan length of the document)\n",
    "    * A sentence matrix has size of $s \\times d$\n",
    "    \n",
    "    \n",
    "* CNN Layer\n",
    "\n",
    "    * Tensor flow cnn: _tf.nn.conv2d_\n",
    "    * Region size: [3, 4, 5] has 3 regions (***Tensor flow define it as height***)\n",
    "    * Width of the filter: d = 300 (***Tensor flow define it as width, usually equal to word embedding dimension***)\n",
    "    * Number of filters per region: f = 150(***This is equalt to number of feature maps for each region size***)\n",
    "    * 1 Max-pooling apply to 1 feature map\n",
    "    \n",
    "    Use the below image just an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn.png\" width = \"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Output Layer: The softmax output layer where:\n",
    "    * o: feature vector from cnn layer after max-poolling is in $k$\n",
    "    * W': $K \\times r$\n",
    "    * y: $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Classification\n",
    "\n",
    "### Approach to Implement\n",
    "\n",
    "* 1-vs-Rest Layer of DOC (This is the method of reference paper)\n",
    "\n",
    "    * M (number of class) sigmoid function, N (batch_size)\n",
    "    * Objective function for training is $$loss = \\sum_{i=1}^M \\sum_{i=1}^N y_n log(p) + (1 - y_n)log(1 - p(y))$$ is the summation of all log loss (cross-entropy) on the training data.\n",
    "    * At prediction, reject if all predicted probability is less than their threshold t_i, otherwise $argmax(Sigmoid(d))$\n",
    "    * The theshold is determined by using outlier detection. (***We can use a fixed number such as 0.95 to validate our model implementation***)\n",
    "\n",
    "We use the similar methodology of 1-vs-Rest as the DOC paper.\n",
    "\n",
    "   * After we trained the language model (paragraph2vec or CNN). We use the feature vectors from the language model and conduce 1-vs-rest classifition using SK-learn for 1-vs-Rest classification analysis\n",
    "   * We remove some class labels as unseen from the training data during the training and cross-validation\n",
    "       * 5 classes labeled + 1 unseen\n",
    "       * 5 classes labeled + 2 unseen\n",
    "       * 5 classes labeled + 3 unseen\n",
    "   * We calibrate the probability and define a probability threshold for each classes in the training set i.e. without the unseen classes.\n",
    "   * We predict the test set classes use the probability threshold: if a data sample is below this threshold for all classes, it belongs to the unseen classes\n",
    "   * We evaluate our prediction using macro-F1 score\n",
    "\n",
    "\n",
    "* Clustering Approach\n",
    "    * Gausian Mix Model\n",
    "    * Infinite Dirichlet process\n",
    "    * We remove some class labels as unseen from the training data during the training and cross-validation\n",
    "       * 5 classes labeled + 1 unseen\n",
    "       * 5 classes labeled + 2 unseen\n",
    "       * 5 classes labeled + 3 unseen\n",
    "    * We use outlier detection approach to identify unseen class\n",
    "    * We evaluate our prediction using macro-F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Evaluation Methods and Metrics\n",
    "\n",
    "### Data Setup\n",
    "\n",
    "* Use 20 newsgroup data\n",
    "* The DOC paper use the top ** _20000_ ** Most frequent vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same basic CNN parameters as in the DOC paper such as region size, number of filters and size of the filter. But We removed the additional hidden layer and we reduce the word length from 2000 to 500 which is the median document length (489) of the 20 newsgroup data set. We made the change to reduce complexity of the network so we can manage with the computer resource we have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding\n",
    "\n",
    "Google word2vec vs. training word embedding on the fly\n",
    "\n",
    "* Google word2vec outperform training word embedding:\n",
    "\n",
    "Using 5 random classes data, we compared the performance using google word2vec and train word embedding layer on the fly method. Google word2vec outperform training word embedding layer by 11% in accuracy with test sets. This is due to the fact google word2vec is based 100 billion google news data data with 3 million vocabulary and phrases whereas training our embedding is only limited to the 20 newsgroup data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare language models\n",
    "\n",
    "We compared the basic performance paragraph2vec and CNN model although the setup is different. \n",
    "\n",
    "* We train the CNN model with google word2vec using a output soltmax layer for classificaiton of 20 newsgroup data. \n",
    "* We train paragraph2vec model with 20 newsgroup data. After the paragraph2vec model is trained. We extract the feature vectors and connect with the same softmax output layer as the CNN output layer.\n",
    "* We keep the feature length of 450 (3 region of 150 filter) for both CNN and paragraph2vec model\n",
    "\n",
    "We learn the following:\n",
    "\n",
    "* CNN is difficult the train with small amount of computer resources. \n",
    "    * We choose to use the median document length of 500 due to the slow computing speed whereas the DOC paper uses 2000.\n",
    "    * We choose to use less number of classes for the same reason\n",
    "* paragraph2vec outperform the CNN network (with limited hyperparameter tuning)\n",
    "    * Paragraph2vec yields 85% test accuracy in 5 classes classification tasks whereas CNN yield yields only 71% test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   \n",
    "### Open classification Experiments\n",
    "\n",
    "* Random sample 64% document as training, 16% for validation, and 20% for testing\n",
    "* Vary number of training classes\n",
    "    * 5 labelled + 1 open\n",
    "    * 5 labelled + 2 open\n",
    "    * 5 labelled + 3 open\n",
    "    * Use Macro-F1 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implementation Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph vector\n",
    "\n",
    "* Paragraph vector 1-vs-rest notebook: **Text_Open_Classification_Paragraph2vec_workbook.ipynb**\n",
    "* Paragraph vector GMM (5 seen + 1 unseen classes): **ParagraphVec_Clustering_5_plus_1.ipynb**\n",
    "* Paragraph vector GMM (5 seen + 2 unseen classes): **ParagraphVec_Clustering_5_plus_2.ipynb**\n",
    "* Paragraph vector GMM (5 seen + 3 unseen classes): **ParagraphVec_Clustering_5_plus_3.ipynb**\n",
    "* Paragraph vector IDP (5 seen + 1 unseen classes): **ParagraphVec_Clustering_5_plus_1-IDP.ipynb**\n",
    "* Paragraph vector IDP (5 seen + 2 unseen classes): **ParagraphVec_Clustering_5_plus_2-IDP.ipynb**\n",
    "* Paragraph vector IDP (5 seen + 3 unseen classes): **ParagraphVec_Clustering_5_plus_3-IDP.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN \n",
    "\n",
    "* CNN Implementation and Training Notebook: **Text_Open_Classification_CNN_workbook.ipynb**\n",
    "* CNN Open classification 1-vs-rest, GMM, IDP (5 seen + 1 unseen classes): **CNN_open_classification_5_plus_1.ipynb**\n",
    "* CNN Open classification 1-vs-rest, GMM, IDP (5 seen + 2 unseen classes): **CNN_open_classification_5_plus_2.ipynb**\n",
    "* CNN Open classification 1-vs-rest, GMM, IDP (5 seen + 3 unseen classes): **CNN_open_classification_5_plus_3.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
