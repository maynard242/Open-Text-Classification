{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragraph Vector 1-vs-Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nlp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'shared_lib.utils' from 'shared_lib/utils.pyc'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "# General libraries.\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.1\"))\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import gensim\n",
    "import nltk\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from pprint import pprint\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Helper libraries\n",
    "from shared_lib import utils, vocabulary, tf_embed_viz\n",
    "nltk.download('stopwords')\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Contruct Paragraph2Vec Model\n",
    "\n",
    "### Preview Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0\t = alt.atheism\n",
      "class: 1\t = comp.graphics\n",
      "class: 2\t = comp.os.ms-windows.misc\n",
      "class: 3\t = comp.sys.ibm.pc.hardware\n",
      "class: 4\t = comp.sys.mac.hardware\n",
      "class: 5\t = comp.windows.x\n",
      "class: 6\t = misc.forsale\n",
      "class: 7\t = rec.autos\n",
      "class: 8\t = rec.motorcycles\n",
      "class: 9\t = rec.sport.baseball\n",
      "class: 10\t = rec.sport.hockey\n",
      "class: 11\t = sci.crypt\n",
      "class: 12\t = sci.electronics\n",
      "class: 13\t = sci.med\n",
      "class: 14\t = sci.space\n",
      "class: 15\t = soc.religion.christian\n",
      "class: 16\t = talk.politics.guns\n",
      "class: 17\t = talk.politics.mideast\n",
      "class: 18\t = talk.politics.misc\n",
      "class: 19\t = talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# Get newsgroup data\n",
    "newsgroup_data_all = fetch_20newsgroups(subset = 'all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# List of all the class labels\n",
    "label_list = list(newsgroup_data_all.target_names)\n",
    "\n",
    "# Print the class labels\n",
    "i = 0\n",
    "for label in label_list:\n",
    "    print \"class: %i\\t = %s\" %(i, label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Select Classes:  ['comp.windows.x', 'talk.politics.mideast', 'comp.sys.ibm.pc.hardware', 'sci.crypt', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'sci.electronics', 'talk.politics.guns']\n",
      "Class labels [5, 17, 3, 11, 2, 4, 12, 16]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "random.seed(8)\n",
    "\n",
    "num_class = 8\n",
    "randomize = True\n",
    "\n",
    "if randomize == True:\n",
    "    label_idxs = []\n",
    "    label_idxs = random.sample(range(1, 19), num_class)\n",
    "else:\n",
    "    label_idxs = range(num_class)\n",
    "\n",
    "select_classes = [label_list[i] for i in label_idxs]\n",
    "print \"Randomly Select Classes: \", select_classes\n",
    "print \"Class labels\", label_idxs\n",
    "\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
    "                                    categories=select_classes)\n",
    "\n",
    "all_data, all_labels = newsgroups_all.data, newsgroups_all.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7743 docs (9.81227e+06 tokens)\n",
      "Training set: 6194 docs (7789033 tokens)\n",
      "Test set: 1549 docs (2023239 tokens)\n",
      "Loaded 6194 docs (7.78903e+06 tokens)\n",
      "Training set: 4955 docs (6043595 tokens)\n",
      "Validation set: 1239 docs (1745438 tokens)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing for Doc2Vec \n",
    "# shuffle and split data\n",
    "train_docs, train_labels, test_docs, test_labels = utils.get_train_test_docs(all_data, \n",
    "                                                                             all_labels, \n",
    "                                                                             split = 0.8, \n",
    "                                                                             shuffle = True)\n",
    "\n",
    "# Further split training set into training and validation set\n",
    "train_docs, train_labels, validation_docs, validation_labels = utils.get_train_val_docs(train_docs, \n",
    "                                                                                         train_labels, \n",
    "                                                                                         split = 0.75, \n",
    "                                                                                         shuffle = True)\n",
    "# clean string\n",
    "# remove stop words and take care of stemming\n",
    "train_docs = utils.preprocess_doc(train_docs, fix_length = False)\n",
    "validation_docs = utils.preprocess_doc(validation_docs, fix_length = False)\n",
    "test_docs = utils.preprocess_doc(test_docs, fix_length = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Please Note LabeledSentence is a data structure of gesim's Doc2vec (paragraph) document format **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import  LabeledSentence\n",
    "import sys\n",
    "\n",
    "all_newsgroup_documents = []\n",
    "\n",
    "#Used to convert newsgroup corpus into Doc2Vec formats\n",
    "def convert_newsgroup(docs,split):\n",
    "    #global doc_count\n",
    "    tagged_documents = []\n",
    "    \n",
    "    for i,v in enumerate(docs):\n",
    "        label = '%s_%s'%(split,i)\n",
    "        tagged_documents.append(LabeledSentence(v, [label]))\n",
    "    \n",
    "    return tagged_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7743 docs: 4955 train, 1239 validation, 1549 test\n"
     ]
    }
   ],
   "source": [
    "test_docs = convert_newsgroup(test_docs,'test')\n",
    "validation_docs = convert_newsgroup(validation_docs,'validation')\n",
    "train_docs = convert_newsgroup(train_docs,'train')\n",
    "\n",
    "all_newsgroup_documents.extend(train_docs)\n",
    "all_newsgroup_documents.extend(validation_docs)\n",
    "all_newsgroup_documents.extend(test_docs)\n",
    "\n",
    "doc_list = all_newsgroup_documents[:]  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train, %d validation, %d test' % (len(doc_list), len(train_docs), len(validation_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Define Paragraph2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import *\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "# Doc2Vec Parameter\n",
    "# dm = 0 use distributed bag of words, dm=1 distributed memory\n",
    "dm_model = Doc2Vec(dm=1, dm_mean=1, sample=1e-5, size=450, window=10, \n",
    "                   negative=5, hs=0, min_count=2, workers=10, max_vocab_size = 20000)\n",
    "dm_model.build_vocab(all_newsgroup_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Paragraph2Vec Model\n",
    "\n",
    "### Please note\n",
    "\n",
    "* Paragraph2vec only the vocabulary of giving data set\n",
    "* e.g. to train 5 + 1, select num_class = 6, to train 5 + 2, select num_class = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import progressbar\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 100)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for epoch in bar(range(passes)):\n",
    "    shuffle(doc_list)\n",
    "    \n",
    "    dm_model.alpha, dm_model.min_alpha = alpha, alpha\n",
    "    dm_model.train(doc_list, total_examples=len(doc_list), epochs = 1)\n",
    "    alpha -= alpha_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract training and test vectors from the Paragraph2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "best_error = defaultdict(lambda :1.0)\n",
    "\n",
    "#Get Vectors From Doc2Vec\n",
    "def extract_vectors(model, docs):    \n",
    "    vectors_list = []\n",
    "    for doc_no in range(len(docs)):\n",
    "        doc_label = docs[doc_no].tags[0] # Use tag to id\n",
    "        doc_vector = model.docvecs[doc_label]\n",
    "        vectors_list.append(doc_vector)      \n",
    "    return vectors_list\n",
    "\n",
    "# TODO inferred vectors\n",
    "def get_infer_vectors(model,docs):   \n",
    "    vecs = []\n",
    "    for doc in docs:\n",
    "        vecs.append(model.infer_vector(doc.words))\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4955, 450)\n",
      "(1239, 450)\n",
      "(4955, 8)\n",
      "(1239, 8)\n"
     ]
    }
   ],
   "source": [
    "train_docs_ids = np.array(extract_vectors(dm_model,train_docs))\n",
    "validation_docs_ids = np.array(extract_vectors(dm_model,validation_docs))\n",
    "\n",
    "# Convert label to one-hot-code\n",
    "train_labels_oh = np.eye(num_class)[train_labels]\n",
    "validation_labels_oh = np.eye(num_class)[validation_labels]\n",
    "\n",
    "print train_docs_ids.shape\n",
    "print validation_docs_ids.shape\n",
    "print train_labels_oh.shape\n",
    "print validation_labels_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following section is for comparing paragraphc2vec's performance with CNN\n",
    "\n",
    "#### 1. Connect with the same output layer as CNN for classification\n",
    "\n",
    "#### 2. This is a multi-nomial classification. (not 1-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = num_class\n",
    "feature_size = 450\n",
    "l2_reg_lambda = 0.1\n",
    "\n",
    "def display_params():\n",
    "    print \"number of classes: \", num_classes\n",
    "    print \"feature size: \", feature_size\n",
    "    print \"regularization: \", l2_reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ is the Paragraph2vec input vectors\n",
    "x_ = tf.placeholder(tf.float32, [None, feature_size], name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes], name=\"y\")\n",
    "l2_loss = tf.constant(0.0)\n",
    "\n",
    "# Output Layer: Softmax (1 layer version)\n",
    "with tf.name_scope(\"Output_layer\"):\n",
    "            \n",
    "    \n",
    "    Z_ = tf.Variable(tf.random_uniform([feature_size, num_classes], -1.0, 1.0), name = \"Z\")\n",
    "    b_ = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "    logits_ = tf.add(tf.matmul(x_, Z_), b_, name=\"logits\")\n",
    "    \n",
    "    # L2 loss\n",
    "    l2_loss += tf.nn.l2_loss(Z_)\n",
    "    l2_loss += tf.nn.l2_loss(b_)\n",
    "    \n",
    "    #scores = tf.nn.xw_plus_b(h_drop, W, b, name=\"scores\")\n",
    "    predictions_ = tf.argmax(logits_, 1, name=\"predictions\")\n",
    "\n",
    "    \n",
    "# Calculate mean cross-entropy loss\n",
    "with tf.name_scope(\"cost_function\"):\n",
    "    per_example_losses_ = tf.nn.softmax_cross_entropy_with_logits(logits=logits_, \n",
    "                                                                 labels=y_,\n",
    "                                                                 name=\"per_example_loss\")\n",
    "    loss_ = tf.reduce_mean(per_example_losses_) + l2_reg_lambda * l2_loss\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_predictions_ = tf.equal(predictions_, tf.argmax(y_, 1))\n",
    "    accuracy_ = tf.reduce_mean(tf.cast(correct_predictions_, \"float\"), name=\"accuracy\")\n",
    "    \n",
    "with tf.name_scope(\"Training\"):\n",
    "    alpha_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.AdagradOptimizer(alpha_)\n",
    "    #optimizer_ = tf.train.AdamOptimizer(alpha_)\n",
    "    train_step_ = optimizer_.minimize(loss_)\n",
    "    \n",
    "# Initializer step\n",
    "init_ = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for training\n",
    "def train_batch(session, batch, alpha):\n",
    "    # Feed last column as targets\n",
    "    feed_dict = {x_:train_docs_ids,\n",
    "                 y_:train_labels_oh,\n",
    "                 alpha_:alpha}\n",
    "    c, a, pred, _ = session.run([loss_, accuracy_, predictions_, train_step_],\n",
    "                       feed_dict=feed_dict)\n",
    "    return c, a, pred\n",
    "\n",
    "def batch_generator(data, batch_size):\n",
    "    \"\"\"Generate minibatches from data.\"\"\"\n",
    "    for i in xrange(0, len(data), batch_size):\n",
    "        yield data[i:i+batch_size]\n",
    "\n",
    "def predict_batch(session):\n",
    "    feed_dict = {x_:validation_docs_ids,\n",
    "                 y_:validation_labels_oh}\n",
    "    a, pred = session.run([accuracy_, predictions_], feed_dict=feed_dict)\n",
    "    return a, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes:  8\n",
      "feature size:  450\n",
      "regularization:  0.1\n"
     ]
    }
   ],
   "source": [
    "display_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shared_lib import utils\n",
    "\n",
    "def run_epochs(num_epochs, batch_size, learning_rate, min_learning, print_rate):\n",
    "    # One epoch = one pass through the training data\n",
    "    num_epochs = num_epochs\n",
    "    batch_size = batch_size\n",
    "    alpha = learning_rate  # learning rate\n",
    "    min_alpha = min_learning\n",
    "    alpha_delta = (alpha - min_alpha) / num_epochs\n",
    "    print_every = print_rate\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # For plotting\n",
    "    train_accuracy = []\n",
    "    validation_accuracy = []\n",
    "\n",
    "    session = tf.Session()\n",
    "    session.run(init_)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        epoch_cost = 0.0\n",
    "        total_batches = 0\n",
    "        print \"\"\n",
    "        print \"---------- Test ----------\"\n",
    "        print \"[epoch %d] Learning Rate %.2f\" %(epoch, alpha)\n",
    "        for i, batch in enumerate(batch_generator(train_docs_ids, batch_size)):\n",
    "            if (i % print_every == 0):\n",
    "                print \"[epoch %d] seen %d minibatches\" % (epoch, i)\n",
    "\n",
    "            cost, accuracy, pred = train_batch(session, batch, alpha)\n",
    "            epoch_cost += cost\n",
    "            total_batches = i + 1\n",
    "\n",
    "        avg_cost = epoch_cost / total_batches\n",
    "        alpha = alpha - alpha_delta\n",
    "\n",
    "        print \"[epoch %d] Completed %d minibatches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch))\n",
    "        print \"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)\n",
    "        print \"[epoch %d] Accuracy %.03f\" %(epoch, accuracy)\n",
    "        print \"[epoch %d] Classificaiton Report\\n\" %(epoch)\n",
    "        print classification_report(train_labels, pred)\n",
    "        train_accuracy.append(accuracy)\n",
    "\n",
    "        print \"\"\n",
    "        print \"---------- Test ----------\"\n",
    "        accuracy, pred = predict_batch(session)\n",
    "        print \"[epoch %d] Validation Accuracy is %.03f\" %(epoch, accuracy)\n",
    "        print \"[epoch %d] Validation Classificaiton Report\\n\" %(epoch)\n",
    "        print classification_report(validation_labels, pred)\n",
    "        validation_accuracy.append(accuracy)\n",
    "    return train_accuracy, validation_accuracy\n",
    "\n",
    "def plot_learning(num_epochs, train_accuracy, validation_accuracy):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(range(0, num_epochs), train_accuracy, '.-', label = \"Training accuracy\")\n",
    "    plt.plot(range(0, num_epochs), validation_accuracy, '.-', label = \"Validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** running epochs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Test ----------\n",
      "[epoch 1] Learning Rate 0.50\n",
      "[epoch 1] seen 0 minibatches\n",
      "[epoch 1] Completed 49 minibatches in 0:00:01\n",
      "[epoch 1] Average cost: 5.999\n",
      "[epoch 1] Accuracy 0.701\n",
      "[epoch 1] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.62      0.57       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 1] Validation Accuracy is 0.666\n",
      "[epoch 1] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.72      0.79      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.82      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 2] Learning Rate 0.47\n",
      "[epoch 2] seen 0 minibatches\n",
      "[epoch 2] Completed 49 minibatches in 0:00:01\n",
      "[epoch 2] Average cost: 1.668\n",
      "[epoch 2] Accuracy 0.701\n",
      "[epoch 2] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 2] Validation Accuracy is 0.665\n",
      "[epoch 2] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 3] Learning Rate 0.43\n",
      "[epoch 3] seen 0 minibatches\n",
      "[epoch 3] Completed 49 minibatches in 0:00:01\n",
      "[epoch 3] Average cost: 1.668\n",
      "[epoch 3] Accuracy 0.701\n",
      "[epoch 3] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 3] Validation Accuracy is 0.665\n",
      "[epoch 3] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 4] Learning Rate 0.40\n",
      "[epoch 4] seen 0 minibatches\n",
      "[epoch 4] Completed 49 minibatches in 0:00:01\n",
      "[epoch 4] Average cost: 1.668\n",
      "[epoch 4] Accuracy 0.701\n",
      "[epoch 4] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 4] Validation Accuracy is 0.665\n",
      "[epoch 4] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 5] Learning Rate 0.37\n",
      "[epoch 5] seen 0 minibatches\n",
      "[epoch 5] Completed 49 minibatches in 0:00:01\n",
      "[epoch 5] Average cost: 1.668\n",
      "[epoch 5] Accuracy 0.701\n",
      "[epoch 5] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 5] Validation Accuracy is 0.665\n",
      "[epoch 5] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 6] Learning Rate 0.33\n",
      "[epoch 6] seen 0 minibatches\n",
      "[epoch 6] Completed 49 minibatches in 0:00:01\n",
      "[epoch 6] Average cost: 1.668\n",
      "[epoch 6] Accuracy 0.701\n",
      "[epoch 6] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 6] Validation Accuracy is 0.665\n",
      "[epoch 6] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 7] Learning Rate 0.30\n",
      "[epoch 7] seen 0 minibatches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] Completed 49 minibatches in 0:00:01\n",
      "[epoch 7] Average cost: 1.668\n",
      "[epoch 7] Accuracy 0.701\n",
      "[epoch 7] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 7] Validation Accuracy is 0.665\n",
      "[epoch 7] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 8] Learning Rate 0.27\n",
      "[epoch 8] seen 0 minibatches\n",
      "[epoch 8] Completed 49 minibatches in 0:00:01\n",
      "[epoch 8] Average cost: 1.668\n",
      "[epoch 8] Accuracy 0.701\n",
      "[epoch 8] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 8] Validation Accuracy is 0.665\n",
      "[epoch 8] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 9] Learning Rate 0.23\n",
      "[epoch 9] seen 0 minibatches\n",
      "[epoch 9] Completed 49 minibatches in 0:00:01\n",
      "[epoch 9] Average cost: 1.668\n",
      "[epoch 9] Accuracy 0.701\n",
      "[epoch 9] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 9] Validation Accuracy is 0.665\n",
      "[epoch 9] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 10] Learning Rate 0.20\n",
      "[epoch 10] seen 0 minibatches\n",
      "[epoch 10] Completed 49 minibatches in 0:00:01\n",
      "[epoch 10] Average cost: 1.668\n",
      "[epoch 10] Accuracy 0.701\n",
      "[epoch 10] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 10] Validation Accuracy is 0.665\n",
      "[epoch 10] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 11] Learning Rate 0.17\n",
      "[epoch 11] seen 0 minibatches\n",
      "[epoch 11] Completed 49 minibatches in 0:00:01\n",
      "[epoch 11] Average cost: 1.668\n",
      "[epoch 11] Accuracy 0.701\n",
      "[epoch 11] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 11] Validation Accuracy is 0.665\n",
      "[epoch 11] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 12] Learning Rate 0.13\n",
      "[epoch 12] seen 0 minibatches\n",
      "[epoch 12] Completed 49 minibatches in 0:00:01\n",
      "[epoch 12] Average cost: 1.668\n",
      "[epoch 12] Accuracy 0.701\n",
      "[epoch 12] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.62      0.58       643\n",
      "          1       0.64      0.61      0.63       624\n",
      "          2       0.76      0.57      0.65       606\n",
      "          3       0.69      0.86      0.77       658\n",
      "          4       0.75      0.73      0.74       639\n",
      "          5       0.67      0.67      0.67       615\n",
      "          6       0.79      0.75      0.77       594\n",
      "          7       0.86      0.78      0.82       576\n",
      "\n",
      "avg / total       0.71      0.70      0.70      4955\n",
      "\n",
      "\n",
      "---------- Test ----------\n",
      "[epoch 12] Validation Accuracy is 0.665\n",
      "[epoch 12] Validation Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.62      0.55       148\n",
      "          1       0.58      0.49      0.53       152\n",
      "          2       0.70      0.54      0.61       158\n",
      "          3       0.60      0.80      0.69       143\n",
      "          4       0.73      0.78      0.75       160\n",
      "          5       0.64      0.60      0.62       169\n",
      "          6       0.81      0.71      0.76       156\n",
      "          7       0.85      0.79      0.82       153\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_accur, validation_accur = run_epochs(num_epochs = epochs, \n",
    "                                           batch_size = 100, \n",
    "                                           learning_rate = 0.5, \n",
    "                                           min_learning = 0.1, \n",
    "                                           print_rate = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40247c5d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning(num_epochs = epochs,\n",
    "              train_accuracy = train_accur, \n",
    "              validation_accuracy = validation_accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open Classificaiton Methods (1-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* 1-vs-Rest Layer of DOC\n",
    "\n",
    "    * M (number of class) sigmoid function, N (batch_size)\n",
    "    * Objective function for training is $$loss = \\sum_{i=1}^M \\sum_{i=1}^N y_n log(p) + (1 - y_n)log(1 - p(y))$$ is the summation of all log loss (cross-entropy) on the training data.\n",
    "    * At prediction, reject if all predicted probability is less than their threshold t_i, otherwise $argmax(Sigmoid(d))$\n",
    "    * The theshold is determined by using outlier detection. (***We can use a fixed number such as 0.95 to validate our model implementation***)\n",
    "    * Approach:\n",
    "        1. Remove some classes from the training data\n",
    "        2. Training the data\n",
    "        3. Add those classes back to the test data\n",
    "\n",
    "* Clustering Approach\n",
    "    * KNN\n",
    "    * Gausian Mix Model\n",
    "    * Infinite Dirichlet process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1 (5 labeled + 1 unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some class and cross validate train data for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SKlearn libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training and test data are feature vectors from paragraph2vec model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3641, 450)\n",
      "(1138, 450)\n"
     ]
    }
   ],
   "source": [
    "## Training and test data are feature vectors from paragraph2vec model\n",
    "train_vectors = extract_vectors(dm_model,train_docs)\n",
    "test_vectors = extract_vectors(dm_model,test_docs)\n",
    "\n",
    "# Define a missing class and remove those data from the training set\n",
    "missing_class = np.array([0])\n",
    "missing_class_idx = np.where(np.isin(train_labels, missing_class))[0]\n",
    "train_new_vectors = [train_vectors[i] for i in range(len(train_vectors)) if i not in missing_class_idx]\n",
    "train_new_labels = [train_labels[i] for i in range(len(train_labels)) if i not in missing_class_idx]\n",
    "\n",
    "train_valid_cut = int(len(train_new_vectors)*.75)\n",
    "train_final_vectors = train_new_vectors[:train_valid_cut]\n",
    "train_final_labels = train_new_labels[:train_valid_cut]\n",
    "\n",
    "valid_final_vectors=train_new_vectors[train_valid_cut:]\n",
    "valid_final_labels = train_new_labels[train_valid_cut:]\n",
    "\n",
    "print np.array(train_vectors).shape\n",
    "print np.array(test_vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1-vs-Rest SVM ---\n",
      "Fitting 3 folds for each of 112 candidates, totalling 336 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qianyu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done 336 out of 336 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64565822354\n",
      "{'estimator__kernel': 'linear', 'estimator__C': 1, 'estimator__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True))\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "parameters_SVC = {\n",
    "    \"estimator__C\": [0.001,0.01,0.1,0.5,1,2,5],\n",
    "    \"estimator__kernel\": [\"poly\",\"rbf\", \"sigmoid\",\"linear\"],\n",
    "    \"estimator__degree\":[1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "print \"--- 1-vs-Rest SVM ---\"\n",
    "mod_svc = GridSearchCV(estimator=clf_svc, param_grid=parameters_SVC, scoring='f1_macro', verbose=True)\n",
    "mod_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "print mod_svc.best_score_ \n",
    "print mod_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_final_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate 1-vs-Rest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qianyu/anaconda2/lib/python2.7/site-packages/sklearn/calibration.py:432: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/home/qianyu/anaconda2/lib/python2.7/site-packages/sklearn/calibration.py:442: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/home/qianyu/anaconda2/lib/python2.7/site-packages/sklearn/calibration.py:444: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True, \n",
    "                              kernel=mod_svc.best_params_['estimator__kernel'], \n",
    "                              C=mod_svc.best_params_['estimator__C'], \n",
    "                              degree=mod_svc.best_params_['estimator__degree']))\n",
    "\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "## Calibrate prob\n",
    "sig_clf_svc = CalibratedClassifierCV(clf_svc, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "sig_clf_svc_probs = sig_clf_svc.predict_proba(test_vectors)\n",
    "clf_svc_probs = clf_svc.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized histogram of max probability (probability that determine the class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAHiCAYAAAANlMFMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5de370810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(sig_clf_svc_probs, axis = 1)\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Classification Accuracy on Test Data\n",
    "\n",
    "* Test Data actually have 5 class labels\n",
    "* Try with training data of 4 labels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[1 2 3 4 5]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       174\n",
      "          1       0.51      0.70      0.59       192\n",
      "          2       0.57      0.60      0.58       199\n",
      "          3       0.53      0.67      0.60       175\n",
      "          4       0.67      0.73      0.70       185\n",
      "          5       0.69      0.79      0.73       213\n",
      "\n",
      "avg / total       0.51      0.59      0.54      1138\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       174\n",
      "          1       0.54      0.70      0.61       192\n",
      "          2       0.50      0.68      0.58       199\n",
      "          3       0.56      0.67      0.61       175\n",
      "          4       0.69      0.69      0.69       185\n",
      "          5       0.74      0.75      0.74       213\n",
      "\n",
      "avg / total       0.51      0.59      0.55      1138\n",
      "\n",
      "0.592267135325\n",
      "0.594024604569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qianyu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "preds1 = clf_svc.predict(test_vectors)\n",
    "preds2 = sig_clf_svc.predict(test_vectors)\n",
    "print np.unique(preds1)\n",
    "print np.unique(preds2)\n",
    "print classification_report(test_labels,preds1)\n",
    "print classification_report(test_labels,preds2)\n",
    "print accuracy_score(test_labels,preds1)\n",
    "print accuracy_score(test_labels,preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the new class, we select a Percentile for Probability Threshold for Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prob_percentile_90 = np.array([np.percentile(sig_clf_svc_probs[:,val], 90.0) \n",
    "                                     for val in range(len(sig_clf_svc_probs[0]))])\n",
    "\n",
    "test_class_preds = np.greater_equal(sig_clf_svc_probs,class_prob_percentile_90).astype(int)\n",
    "\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "valid_class_probs = np.multiply(sig_clf_svc_probs, test_class_preds)\n",
    "valid_class = np.greater_equal(np.ceil(valid_class_probs),1).astype(int)\n",
    "predicted_multinomial = np.multiply(valid_class, np.unique(train_final_labels))\n",
    "predicted_test_class = np.max(predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predicted_test_class), np.unique(train_final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate F1 Score/Precision/Recall with Unseen Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_class_idx_test = np.where(np.isin(test_labels, missing_class))[0]\n",
    "for i in range(len(test_labels)): \n",
    "    if i in missing_class_idx_test:\n",
    "        test_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.80      0.38       174\n",
      "          1       0.80      0.47      0.59       192\n",
      "          2       0.73      0.42      0.53       199\n",
      "          3       0.64      0.41      0.50       175\n",
      "          4       0.82      0.51      0.63       185\n",
      "          5       0.89      0.48      0.62       213\n",
      "\n",
      "avg / total       0.70      0.51      0.55      1138\n",
      "\n",
      "0.510544815466\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, predicted_test_class)\n",
    "print accuracy_score(test_labels, predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Class Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140   8   6  10   5   5]\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(sorted(predicted_test_class[unseen_class_indices]))\n",
    "print sum(np.bincount(sorted(predicted_test_class[unseen_class_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unseen Class Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.0 174\n",
      "0.804597701149\n"
     ]
    }
   ],
   "source": [
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0]), \\\n",
    "    sum(np.isin(test_labels, missing_class).astype(int))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0])/sum(np.isin(test_labels, missing_class).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2 (5 labeled + 2 unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some class and cross validate train data for hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training and test data are feature vectors from paragraph2vec model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4265, 450)\n",
      "(1333, 450)\n"
     ]
    }
   ],
   "source": [
    "## Training and test data are feature vectors from paragraph2vec model\n",
    "train_vectors = extract_vectors(dm_model,train_docs)\n",
    "test_vectors = extract_vectors(dm_model,test_docs)\n",
    "\n",
    "# Define a missing class and remove those data from the training set\n",
    "missing_class = np.array([0, 1])\n",
    "missing_class_idx = np.where(np.isin(train_labels, missing_class))[0]\n",
    "train_new_vectors = [train_vectors[i] for i in range(len(train_vectors)) if i not in missing_class_idx]\n",
    "train_new_labels = [train_labels[i] for i in range(len(train_labels)) if i not in missing_class_idx]\n",
    "\n",
    "train_valid_cut = int(len(train_new_vectors)*.75)\n",
    "train_final_vectors = train_new_vectors[:train_valid_cut]\n",
    "train_final_labels = train_new_labels[:train_valid_cut]\n",
    "\n",
    "valid_final_vectors=train_new_vectors[train_valid_cut:]\n",
    "valid_final_labels = train_new_labels[train_valid_cut:]\n",
    "\n",
    "print np.array(train_vectors).shape\n",
    "print np.array(test_vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1-vs-Rest SVM ---\n",
      "Fitting 3 folds for each of 112 candidates, totalling 336 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 336 out of 336 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694632064874\n",
      "{'estimator__kernel': 'linear', 'estimator__C': 0.1, 'estimator__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True))\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "parameters_SVC = {\n",
    "    \"estimator__C\": [0.001,0.01,0.1,0.5,1,2,5],\n",
    "    \"estimator__kernel\": [\"poly\",\"rbf\", \"sigmoid\",\"linear\"],\n",
    "    \"estimator__degree\":[1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "print \"--- 1-vs-Rest SVM ---\"\n",
    "mod_svc = GridSearchCV(estimator=clf_svc, param_grid=parameters_SVC, scoring='f1_macro', verbose=True)\n",
    "mod_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "print mod_svc.best_score_ \n",
    "print mod_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_final_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate 1-vs-Rest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True, \n",
    "                              kernel=mod_svc.best_params_['estimator__kernel'], \n",
    "                              C=mod_svc.best_params_['estimator__C'], \n",
    "                              degree=mod_svc.best_params_['estimator__degree']))\n",
    "\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "## Calibrate prob\n",
    "sig_clf_svc = CalibratedClassifierCV(clf_svc, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "sig_clf_svc_probs = sig_clf_svc.predict_proba(test_vectors)\n",
    "clf_svc_probs = clf_svc.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized histogram of max probability (probability that determine the class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAHiCAYAAAANlMFMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5daf9bb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(sig_clf_svc_probs, axis = 1)\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Classification Accuracy on Test Data\n",
    "\n",
    "* Test Data actually have 5 class labels\n",
    "* Try with training data of 4 labels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6]\n",
      "[2 3 4 5 6]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       156\n",
      "          1       0.00      0.00      0.00       197\n",
      "          2       0.49      0.59      0.53       221\n",
      "          3       0.56      0.58      0.57       201\n",
      "          4       0.56      0.71      0.62       180\n",
      "          5       0.43      0.88      0.58       180\n",
      "          6       0.65      0.83      0.73       198\n",
      "\n",
      "avg / total       0.39      0.52      0.44      1333\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       156\n",
      "          1       0.00      0.00      0.00       197\n",
      "          2       0.52      0.56      0.54       221\n",
      "          3       0.45      0.64      0.53       201\n",
      "          4       0.61      0.66      0.63       180\n",
      "          5       0.43      0.89      0.58       180\n",
      "          6       0.67      0.82      0.74       198\n",
      "\n",
      "avg / total       0.39      0.52      0.44      1333\n",
      "\n",
      "0.523630907727\n",
      "0.520630157539\n"
     ]
    }
   ],
   "source": [
    "preds1 = clf_svc.predict(test_vectors)\n",
    "preds2 = sig_clf_svc.predict(test_vectors)\n",
    "print np.unique(preds1)\n",
    "print np.unique(preds2)\n",
    "print classification_report(test_labels,preds1)\n",
    "print classification_report(test_labels,preds2)\n",
    "print accuracy_score(test_labels,preds1)\n",
    "print accuracy_score(test_labels,preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the new class, we select a Percentile for Probability Threshold for Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prob_percentile_90 = np.array([np.percentile(sig_clf_svc_probs[:,val], 90.0) \n",
    "                                     for val in range(len(sig_clf_svc_probs[0]))])\n",
    "\n",
    "test_class_preds = np.greater_equal(sig_clf_svc_probs,class_prob_percentile_90).astype(int)\n",
    "\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "valid_class_probs = np.multiply(sig_clf_svc_probs, test_class_preds)\n",
    "valid_class = np.greater_equal(np.ceil(valid_class_probs),1).astype(int)\n",
    "predicted_multinomial = np.multiply(valid_class, np.unique(train_final_labels))\n",
    "predicted_test_class = np.max(predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3, 4, 5, 6]), array([2, 3, 4, 5, 6]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predicted_test_class), np.unique(train_final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate F1 Score/Precision/Recall with Unseen Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_class_idx_test = np.where(np.isin(test_labels, missing_class))[0]\n",
    "for i in range(len(test_labels)): \n",
    "    if i in missing_class_idx_test:\n",
    "        test_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.73      0.51       353\n",
      "          2       0.66      0.39      0.49       221\n",
      "          3       0.72      0.48      0.57       201\n",
      "          4       0.71      0.53      0.61       180\n",
      "          5       0.80      0.59      0.68       180\n",
      "          6       0.90      0.61      0.73       198\n",
      "\n",
      "avg / total       0.66      0.57      0.58      1333\n",
      "\n",
      "0.573893473368\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, predicted_test_class)\n",
    "print accuracy_score(test_labels, predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Class Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259   0  30  16  22  22   4]\n",
      "353\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(sorted(predicted_test_class[unseen_class_indices]))\n",
    "print sum(np.bincount(sorted(predicted_test_class[unseen_class_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unseen Class Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259.0 353\n",
      "0.733711048159\n"
     ]
    }
   ],
   "source": [
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0]), \\\n",
    "    sum(np.isin(test_labels, missing_class).astype(int))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0])/sum(np.isin(test_labels, missing_class).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3 (5 labeled + 3 unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some class and cross validate train data for hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training and test data are feature vectors from paragraph2vec model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4955, 450)\n",
      "(1549, 450)\n"
     ]
    }
   ],
   "source": [
    "## Training and test data are feature vectors from paragraph2vec model\n",
    "train_vectors = extract_vectors(dm_model,train_docs)\n",
    "test_vectors = extract_vectors(dm_model,test_docs)\n",
    "\n",
    "# Define a missing class and remove those data from the training set\n",
    "missing_class = np.array([0, 1, 2])\n",
    "missing_class_idx = np.where(np.isin(train_labels, missing_class))[0]\n",
    "train_new_vectors = [train_vectors[i] for i in range(len(train_vectors)) if i not in missing_class_idx]\n",
    "train_new_labels = [train_labels[i] for i in range(len(train_labels)) if i not in missing_class_idx]\n",
    "\n",
    "train_valid_cut = int(len(train_new_vectors)*.75)\n",
    "train_final_vectors = train_new_vectors[:train_valid_cut]\n",
    "train_final_labels = train_new_labels[:train_valid_cut]\n",
    "\n",
    "valid_final_vectors=train_new_vectors[train_valid_cut:]\n",
    "valid_final_labels = train_new_labels[train_valid_cut:]\n",
    "\n",
    "print np.array(train_vectors).shape\n",
    "print np.array(test_vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1-vs-Rest SVM ---\n",
      "Fitting 3 folds for each of 112 candidates, totalling 336 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 336 out of 336 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793218455564\n",
      "{'estimator__kernel': 'rbf', 'estimator__C': 2, 'estimator__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True))\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "parameters_SVC = {\n",
    "    \"estimator__C\": [0.001,0.01,0.1,0.5,1,2,5],\n",
    "    \"estimator__kernel\": [\"poly\",\"rbf\", \"sigmoid\",\"linear\"],\n",
    "    \"estimator__degree\":[1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "print \"--- 1-vs-Rest SVM ---\"\n",
    "mod_svc = GridSearchCV(estimator=clf_svc, param_grid=parameters_SVC, scoring='f1_macro', verbose=True)\n",
    "mod_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "print mod_svc.best_score_ \n",
    "print mod_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7]\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_final_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate 1-vs-Rest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True, \n",
    "                              kernel=mod_svc.best_params_['estimator__kernel'], \n",
    "                              C=mod_svc.best_params_['estimator__C'], \n",
    "                              degree=mod_svc.best_params_['estimator__degree']))\n",
    "\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "## Calibrate prob\n",
    "sig_clf_svc = CalibratedClassifierCV(clf_svc, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "sig_clf_svc_probs = sig_clf_svc.predict_proba(test_vectors)\n",
    "clf_svc_probs = clf_svc.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized histogram of max probability (probability that determine the class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f402463f810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(sig_clf_svc_probs, axis = 1)\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Classification Accuracy on Test Data\n",
    "\n",
    "* Test Data actually have 5 class labels\n",
    "* Try with training data of 4 labels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7]\n",
      "[3 4 5 6 7]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       194\n",
      "          1       0.00      0.00      0.00       206\n",
      "          2       0.00      0.00      0.00       199\n",
      "          3       0.37      0.94      0.53       187\n",
      "          4       0.71      0.74      0.73       192\n",
      "          5       0.34      0.80      0.48       200\n",
      "          6       0.72      0.77      0.75       160\n",
      "          7       0.76      0.83      0.79       211\n",
      "\n",
      "avg / total       0.35      0.50      0.40      1549\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       194\n",
      "          1       0.00      0.00      0.00       206\n",
      "          2       0.00      0.00      0.00       199\n",
      "          3       0.42      0.92      0.58       187\n",
      "          4       0.77      0.73      0.75       192\n",
      "          5       0.30      0.83      0.45       200\n",
      "          6       0.70      0.78      0.74       160\n",
      "          7       0.75      0.84      0.80       211\n",
      "\n",
      "avg / total       0.36      0.50      0.40      1549\n",
      "\n",
      "0.50161394448\n",
      "0.503550677857\n"
     ]
    }
   ],
   "source": [
    "preds1 = clf_svc.predict(test_vectors)\n",
    "preds2 = sig_clf_svc.predict(test_vectors)\n",
    "print np.unique(preds1)\n",
    "print np.unique(preds2)\n",
    "print classification_report(test_labels,preds1)\n",
    "print classification_report(test_labels,preds2)\n",
    "print accuracy_score(test_labels,preds1)\n",
    "print accuracy_score(test_labels,preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the new class, we select a Percentile for Probability Threshold for Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prob_percentile_90 = np.array([np.percentile(sig_clf_svc_probs[:,val], 90.0) \n",
    "                                     for val in range(len(sig_clf_svc_probs[0]))])\n",
    "\n",
    "test_class_preds = np.greater_equal(sig_clf_svc_probs,class_prob_percentile_90).astype(int)\n",
    "\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "valid_class_probs = np.multiply(sig_clf_svc_probs, test_class_preds)\n",
    "valid_class = np.greater_equal(np.ceil(valid_class_probs),1).astype(int)\n",
    "predicted_multinomial = np.multiply(valid_class, np.unique(train_final_labels))\n",
    "predicted_test_class = np.max(predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3, 4, 5, 6, 7]), array([3, 4, 5, 6, 7]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predicted_test_class), np.unique(train_final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate F1 Score/Precision/Recall with Unseen Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_class_idx_test = np.where(np.isin(test_labels, missing_class))[0]\n",
    "for i in range(len(test_labels)): \n",
    "    if i in missing_class_idx_test:\n",
    "        test_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.76      0.66       599\n",
      "          3       0.69      0.57      0.63       187\n",
      "          4       0.87      0.69      0.77       192\n",
      "          5       0.50      0.39      0.44       200\n",
      "          6       0.79      0.76      0.77       160\n",
      "          7       0.94      0.69      0.79       211\n",
      "\n",
      "avg / total       0.69      0.67      0.67      1549\n",
      "\n",
      "0.671400903809\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, predicted_test_class)\n",
    "print accuracy_score(test_labels, predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Class Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[455   0   0  47  10  76   7   4]\n",
      "599\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(sorted(predicted_test_class[unseen_class_indices]))\n",
    "print sum(np.bincount(sorted(predicted_test_class[unseen_class_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unseen Class Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455.0 599\n",
      "0.75959933222\n"
     ]
    }
   ],
   "source": [
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0]), \\\n",
    "    sum(np.isin(test_labels, missing_class).astype(int))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0])/sum(np.isin(test_labels, missing_class).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
