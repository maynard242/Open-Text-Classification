{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Classification with CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shared_lib.utils' from 'shared_lib/utils.pyc'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, json, time, shutil\n",
    "import itertools, collections\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.1\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# Helper libraries\n",
    "from shared_lib import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "import copy\n",
    "\n",
    "# Import model\n",
    "#import cnnlm\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SKlearn libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'Data_Set/'\n",
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_DATA = os.path.join(PROJECT_PATH, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0\t = alt.atheism\n",
      "class: 1\t = comp.graphics\n",
      "class: 2\t = comp.os.ms-windows.misc\n",
      "class: 3\t = comp.sys.ibm.pc.hardware\n",
      "class: 4\t = comp.sys.mac.hardware\n",
      "class: 5\t = comp.windows.x\n",
      "class: 6\t = misc.forsale\n",
      "class: 7\t = rec.autos\n",
      "class: 8\t = rec.motorcycles\n",
      "class: 9\t = rec.sport.baseball\n",
      "class: 10\t = rec.sport.hockey\n",
      "class: 11\t = sci.crypt\n",
      "class: 12\t = sci.electronics\n",
      "class: 13\t = sci.med\n",
      "class: 14\t = sci.space\n",
      "class: 15\t = soc.religion.christian\n",
      "class: 16\t = talk.politics.guns\n",
      "class: 17\t = talk.politics.mideast\n",
      "class: 18\t = talk.politics.misc\n",
      "class: 19\t = talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Get newsgroup data\n",
    "newsgroup_data_all = fetch_20newsgroups(subset = 'all', remove=('headers', 'footers', 'quotes'))\n",
    "all_data, all_labels = newsgroup_data_all.data, newsgroup_data_all.target\n",
    "\n",
    "# List of all the class labels\n",
    "label_list = list(newsgroup_data_all.target_names)\n",
    "\n",
    "# Print the class labels\n",
    "i = 0\n",
    "for label in label_list:\n",
    "    print \"class: %i\\t = %s\" %(i, label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup_all.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "f = open('./Data_Set/newsgroup_prep/newsgroup_all.txt', 'w') \n",
    "for doc in all_data:\n",
    "    # Clean up str\n",
    "    doc = utils.clean_str((doc).encode('utf-8'))\n",
    "    # remove stop words and do stemming optionaly\n",
    "    doc = utils.preprocess_stop_stem(doc, stop=True, sent=True, stem=False)\n",
    "    f.write(\"%s\\n\" %(doc))\n",
    "f.close()\n",
    "\n",
    "# RegEx or list of file names\n",
    "data_20newsgroup = os.path.join(PROJECT_DATA, 'newsgroup_prep/')\n",
    "\n",
    "corpus = PlaintextCorpusReader(data_20newsgroup, 'newsgroup_all.txt')\n",
    "\n",
    "for infile in sorted(corpus.fileids()):\n",
    "    print infile # The fileids of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 20000 words\n"
     ]
    }
   ],
   "source": [
    "V = 20000\n",
    "vocab = vocabulary.Vocabulary((utils.canonicalize_word(w) \n",
    "                               for w in utils.flatten(corpus.sents())),\n",
    "                               size = V)\n",
    "print \"Vocabulary: %d words\" % vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Select Classes:  ['comp.windows.x', 'talk.politics.mideast', 'comp.sys.ibm.pc.hardware', 'sci.crypt', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'sci.electronics', 'talk.politics.guns']\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# Select training and test data based on the number of classes\n",
    "# Including randomization option\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(8)\n",
    "\n",
    "num_class = 8\n",
    "randomize = True\n",
    "\n",
    "if randomize == True:\n",
    "    label_idxs = []\n",
    "    label_idxs = random.sample(range(1, 19), num_class)\n",
    "else:\n",
    "    label_idxs = range(num_class)\n",
    "\n",
    "select_classes = [label_list[i] for i in label_idxs]\n",
    "print \"Randomly Select Classes: \", select_classes\n",
    "\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
    "                                    categories=select_classes)\n",
    "\n",
    "all_data, all_labels = newsgroups_all.data, newsgroups_all.target\n",
    "print np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7743 docs (2.36154e+07 tokens)\n",
      "Training set: 6194 docs (18888526 tokens)\n",
      "Test set: 1549 docs (4726834 tokens)\n"
     ]
    }
   ],
   "source": [
    "doc_length = 500\n",
    "\n",
    "# Preprocess data\n",
    "# Cleaning special characters\n",
    "# Cut or pad based on document length\n",
    "all_docs = utils.preprocess_doc(all_data, length = doc_length)\n",
    "\n",
    "# Split total data set to training and test set\n",
    "train_docs, train_labels, test_docs, test_labels = utils.get_train_test_docs(all_docs, \n",
    "                                                                             all_labels, \n",
    "                                                                             split = 0.8, \n",
    "                                                                             shuffle = True)\n",
    "orig_test_labels = copy.copy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Training Docs shape: (6194, 500) should equal to (batch_size, doc_length)\n",
      "Input Training labels shape: (6194, 8) should equal to (batch_size, num_class)\n",
      "Input Testing Docs shape: (1549, 500) should equal to (batch_size, doc_length)\n",
      "Input Testing labels shape: (1549, 8) should equal to (batch_size, num_class)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize documents and conver to ID\n",
    "# We tokenize each docs in the dataset and convert to vocab ID\n",
    "# matrix of batch_size x doc_length\n",
    "train_docs_ids = utils.docs_to_ids(train_docs, vocab)\n",
    "test_docs_ids = utils.docs_to_ids(test_docs, vocab)\n",
    "\n",
    "# Convert label to one-hot-code\n",
    "train_labels_oh = np.eye(num_class)[train_labels]\n",
    "test_labels_oh = np.eye(num_class)[test_labels]\n",
    "\n",
    "\n",
    "print \"Input Training Docs shape:\", train_docs_ids.shape, \"should equal to (batch_size, doc_length)\"\n",
    "print \"Input Training labels shape:\", train_labels_oh.shape, \"should equal to (batch_size, num_class)\"\n",
    "print \"Input Testing Docs shape:\", test_docs_ids.shape, \"should equal to (batch_size, doc_length)\"\n",
    "print \"Input Testing labels shape:\", test_labels_oh.shape, \"should equal to (batch_size, num_class)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Google Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_google_bin(fname, vocab):\n",
    "    \"\"\"\n",
    "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
    "    \"\"\"\n",
    "    word_vecs = {}\n",
    "    with open(fname, \"rb\") as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, layer1_size = map(int, header.split())\n",
    "        print \"Google Word2vec Vocabulary Size:\", vocab_size\n",
    "        print \"Vector size:\", layer1_size\n",
    "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
    "        print \"Binary Length of word vector:\", binary_len\n",
    "        for line in xrange(vocab_size):\n",
    "            word = []\n",
    "            while True: # Read 1 char a time\n",
    "                ch = f.read(1) \n",
    "                if ch == ' ': # If it is a space, a word is read, we join then to read its vector\n",
    "                    word = ''.join(word)\n",
    "                    break\n",
    "                if ch != '\\n': # If it is not \\n, grouping character\n",
    "                    word.append(ch) \n",
    "            if word in vocab.wordset: # If a word in the 20 newsgroup vocab, get its vector\n",
    "                word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')  \n",
    "            else:\n",
    "                f.read(binary_len)\n",
    "    f.close()\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Word2vec Vocabulary Size: 3000000\n",
      "Vector size: 300\n",
      "Binary Length of word vector: 1200\n"
     ]
    }
   ],
   "source": [
    "google_word2vec = load_google_bin('./google_word2vec/GoogleNews-vectors-negative300.bin', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of vocabulary in 20newsgroup: 20000\n",
      "Total matched vocabulary from google word2vec: 16555\n",
      "--- Print a sample of google_word2vec vocabulary ---\n",
      "Word: raining \t\t Vector: [ 0.02331543  0.05004883 -0.00059891] ...\n",
      "Word: writings \t\t Vector: [ 0.18945312  0.2109375   0.20507812] ...\n",
      "Word: divinely \t\t Vector: [-0.02783203 -0.40820312 -0.01037598] ...\n",
      "Word: foul \t\t Vector: [ 0.18847656 -0.28710938  0.33007812] ...\n",
      "Word: four \t\t Vector: [ 0.0859375  -0.07275391  0.01672363] ...\n",
      "Word: gag \t\t Vector: [ 0.14648438 -0.08203125 -0.00897217] ...\n",
      "Word: prefix \t\t Vector: [ 0.34570312  0.1640625   0.11425781] ...\n",
      "Word: woods \t\t Vector: [ 0.11328125 -0.01165771 -0.20800781] ...\n",
      "Word: verses \t\t Vector: [ 0.28710938  0.15820312  0.23828125] ...\n",
      "Word: hanging \t\t Vector: [ 0.08984375  0.13769531 -0.14941406] ...\n",
      "Word: woody \t\t Vector: [ 0.08251953  0.44140625  0.07421875] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Total Number of vocabulary in 20newsgroup:\", vocab.size\n",
    "print \"Total matched vocabulary from google word2vec:\", len(google_word2vec.keys())\n",
    "print \"--- Print a sample of google_word2vec vocabulary ---\"\n",
    "i = 0\n",
    "for k, v in google_word2vec.iteritems():\n",
    "    if i <= 10:\n",
    "        print \"Word: %s \\t\\t Vector: %s ...\" %(k, v[:3])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unknown_words(google_word2vec, vocab, k=300):\n",
    "    for word in vocab.wordset:\n",
    "        if word not in google_word2vec:\n",
    "            google_word2vec[word] = np.random.uniform(-0.25,0.25,k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of vocabulary in 20newsgroup: 20000\n",
      "Total matched vocabulary from google word2vec: 20000\n",
      "Pre-trained word2vec size (20000, 300)\n"
     ]
    }
   ],
   "source": [
    "add_unknown_words(google_word2vec, vocab, k=300)\n",
    "print \"Total Number of vocabulary in 20newsgroup:\", vocab.size\n",
    "print \"Total matched vocabulary from google word2vec:\", len(google_word2vec.keys())\n",
    "pt_word2vec = np.array(google_word2vec.values())\n",
    "print \"Pre-trained word2vec size\", pt_word2vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_length = 500 # s\n",
    "num_classes = num_class # M\n",
    "vocab_size = 20000\n",
    "embedding_size = 300 # d\n",
    "embedding_train = False # We use pretrained word2vec\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_filters = 150\n",
    "l2_reg_lambda = 0.5\n",
    "dropout_prob = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for input, output and dropout\n",
    "# x_: Document, Size: (batch, document_length) word in indice\n",
    "# y_: Classes, Size: (batch, num_of_classes)\n",
    "# dropout_keep_prob: Dropout regularization parameter\n",
    "x_ = tf.placeholder(tf.int32, [None, doc_length], name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes], name=\"y\")\n",
    "dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "# Keeping track of l2 regularization loss (optional)\n",
    "l2_loss = tf.constant(0.0)\n",
    "\n",
    "# Embedding layer (Train embedding layer)\n",
    "# Need different implementation if use google pretrained word2vec\n",
    "with tf.name_scope(\"Embedding_Layer\"):\n",
    "    # The vocab to vector table for lookup (to be trained or pre-trained)\n",
    "    if embedding_train:\n",
    "        C_ = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"C\")\n",
    "    else:\n",
    "        C_ = tf.placeholder(tf.float32, [vocab_size, embedding_size], name=\"C\")\n",
    "\n",
    "    # Embedding output needs to be in size: (batch, doc_length, embedding_size, 1)\n",
    "    # Lookup gives (batch, doc_length, embedding_size)\n",
    "    # Therefore, we need to expand the dimension to 4D to work with conv2d\n",
    "    embedded_out = tf.expand_dims(tf.nn.embedding_lookup(C_, x_), -1)\n",
    "\n",
    "# Create a convolution + maxpool layer for each filter size\n",
    "pooled_outputs = []\n",
    "for i, filter_size in enumerate(filter_sizes):\n",
    "    with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "\n",
    "        # Convolution Layer\n",
    "        # input shape: (batch, height(doc length, width(embedding size), channels(1) )\n",
    "        # filter shape: (filter_height, filter width(same as embedding size), in_channel, out_channels)\n",
    "        # in_channel = 1 for our data\n",
    "        # out_channel = num_filters\n",
    "        filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "\n",
    "        # To experiment with normal distribution\n",
    "        W_ = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "        b_ = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "\n",
    "        # \"VALID\" padding means no padding at edge\n",
    "        # Return shape (batch, height(doc length, width(embedding size), 1)\n",
    "        conv_ = tf.nn.conv2d(embedded_out, W_, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv\")\n",
    "\n",
    "        # Apply nonlinearity using Relu (train fasster than tanh)\n",
    "        # Return shape (batch, height(doc length, 1, 1)\n",
    "        h_ = tf.nn.relu(tf.nn.bias_add(conv_, b_), name=\"relu\")\n",
    "\n",
    "        # Maxpooling over the outputs\n",
    "        # ksize is window for pooling, we took 1 value for width direction\n",
    "        # For height, apply to each convolution steps to stripe the whole input matrix.\n",
    "        # Return shape (1, doc_length-filter_size+1, 1, 1)\n",
    "        pooled = tf.nn.max_pool(h_, \n",
    "                                ksize=[1, doc_length - filter_size + 1, 1, 1],\n",
    "                                strides=[1, 1, 1, 1], \n",
    "                                padding='VALID', \n",
    "                                name=\"pool\")\n",
    "        pooled_outputs.append(pooled)\n",
    "\n",
    "# Combine all the pooled features\n",
    "# find the total number of filters = num_of_filters * num_of_region\n",
    "# If we use [2, 3, 4] and 2 filter per region, we have 3 * 2 = 6 filters\n",
    "num_filters_total = num_filters * len(filter_sizes)\n",
    "\n",
    "# combine pooling output to feature vectors\n",
    "# h_pool_flat in shape of (batch_size, ? , num_filters_total)\n",
    "h_pool = tf.concat(pooled_outputs, 3)\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])\n",
    "\n",
    "# Add dropout\n",
    "with tf.name_scope(\"dropout\"):\n",
    "    h_drop = tf.nn.dropout(h_pool_flat, dropout_keep_prob)\n",
    "\n",
    "# Output Layer: Softmax\n",
    "# Final (unnormalized) scores and predictions\n",
    "# Do we need to normalize?\n",
    "with tf.name_scope(\"Output_layer\"):\n",
    "    Z_ = tf.Variable(tf.random_uniform([num_filters_total, num_classes], -1.0, 1.0), name = \"Z\")\n",
    "    b_output_ = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b_output\")\n",
    "    logits_ = tf.add(tf.matmul(h_drop, Z_), b_output_, name=\"logits\")\n",
    "\n",
    "    # L2 loss\n",
    "    l2_loss += tf.nn.l2_loss(Z_)\n",
    "    l2_loss += tf.nn.l2_loss(b_)\n",
    "\n",
    "    #scores = tf.nn.xw_plus_b(h_drop, W, b, name=\"scores\")\n",
    "    predictions_ = tf.argmax(logits_, 1, name=\"predictions\")\n",
    "\n",
    "# Calculate mean cross-entropy loss\n",
    "with tf.name_scope(\"cost_function\"):\n",
    "    per_example_losses_ = tf.nn.softmax_cross_entropy_with_logits(logits=logits_, \n",
    "                                                                 labels=y_,\n",
    "                                                                 name=\"per_example_loss\")\n",
    "    loss_ = tf.reduce_mean(per_example_losses_) + l2_reg_lambda * l2_loss\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_predictions_ = tf.equal(predictions_, tf.argmax(y_, 1))\n",
    "    accuracy_ = tf.reduce_mean(tf.cast(correct_predictions_, \"float\"), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"Training\"):\n",
    "    alpha_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.AdagradOptimizer(alpha_)\n",
    "    #optimizer_ = tf.train.AdamOptimizer(alpha_)\n",
    "    train_step_ = optimizer_.minimize(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model (5 labeled + 1 unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./CNN_5p3_model/model\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./CNN_5p3_model/model\")\n",
    "    print(\"Model restored.\")\n",
    "    feed_dict_train = {x_:train_docs_ids,\n",
    "                   y_:train_labels_oh,\n",
    "                   C_:pt_word2vec,\n",
    "                   dropout_keep_prob:dropout_prob}\n",
    "    train_vectors = sess.run([h_drop], feed_dict=feed_dict_train)[0]\n",
    "    feed_dict_test = {x_:test_docs_ids,\n",
    "                   y_:test_labels_oh,\n",
    "                   C_:pt_word2vec,\n",
    "                   dropout_keep_prob:dropout_prob}\n",
    "    test_vectors = sess.run([h_drop], feed_dict=feed_dict_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vector shape:  (6194, 450)\n",
      "test_vector shape:  (1549, 450)\n",
      "train_label shape:  (6194,)\n",
      "test_label shape:  (1549,)\n"
     ]
    }
   ],
   "source": [
    "print \"train_vector shape: \", train_vectors.shape\n",
    "print \"test_vector shape: \", test_vectors.shape\n",
    "print \"train_label shape: \", train_labels.shape\n",
    "print \"test_label shape: \", test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-vs-Rest Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6194, 450)\n",
      "(3103, 450)\n",
      "(3103,)\n",
      "(1239, 450)\n",
      "(1239,)\n",
      "(752, 450)\n",
      "(752,)\n",
      "(1549, 450)\n",
      "(1549,)\n",
      "[1 3 4 6 7]\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[1 3 4 6 7]\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "train_valid_cut = int(len(train_vectors)*0.8)\n",
    "valid_final_vectors=train_vectors[train_valid_cut:]\n",
    "valid_final_labels = train_labels[train_valid_cut:]\n",
    "\n",
    "train_new_vectors = train_vectors[:train_valid_cut]\n",
    "train_new_labels = train_labels[:train_valid_cut]\n",
    "\n",
    "missing_class = np.array([0, 2, 5])\n",
    "missing_class_idx = np.where(np.isin(train_new_labels, missing_class))[0]\n",
    "train_final_vectors = [train_new_vectors[i] for i in range(len(train_new_vectors)) if i not in missing_class_idx]\n",
    "train_final_labels = [train_new_labels[i] for i in range(len(train_new_labels)) if i not in missing_class_idx]\n",
    "\n",
    "val_missing_class_idx = np.where(np.isin(valid_final_labels, missing_class))[0]\n",
    "valid_calib_vectors = [valid_final_vectors[i] for i in range(len(valid_final_vectors)) if i not in val_missing_class_idx]\n",
    "valid_calib_labels = [valid_final_labels[i] for i in range(len(valid_final_labels)) if i not in val_missing_class_idx]\n",
    "\n",
    "\n",
    "\n",
    "print np.array(train_vectors).shape\n",
    "print np.array(train_final_vectors).shape\n",
    "print np.array(train_final_labels).shape\n",
    "\n",
    "print np.array(valid_final_vectors).shape\n",
    "print np.array(valid_final_labels).shape\n",
    "\n",
    "print np.array(valid_calib_vectors).shape\n",
    "print np.array(valid_calib_labels).shape\n",
    "\n",
    "\n",
    "print np.array(test_vectors).shape\n",
    "print np.array(test_labels).shape\n",
    "print np.unique(train_final_labels)\n",
    "print np.unique(valid_final_labels)\n",
    "print np.unique(valid_calib_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1-vs-Rest SVM ---\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511030735581\n",
      "{'estimator__kernel': 'linear', 'estimator__C': 0.5, 'estimator__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "# Method SVM 1-vs-Rest\n",
    "clf_svc = OneVsRestClassifier(SVC(probability=True))\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "parameters_SVC = {\n",
    "    \"estimator__C\": [0.5, 1, 2],\n",
    "    \"estimator__kernel\": [\"poly\",\"rbf\", \"sigmoid\", \"linear\"],\n",
    "    \"estimator__degree\":[1, 2, 3],\n",
    "}\n",
    "\n",
    "print \"--- 1-vs-Rest SVM ---\"\n",
    "mod_svc = GridSearchCV(estimator=clf_svc, param_grid=parameters_SVC, scoring='f1_macro', verbose=True)\n",
    "mod_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "print mod_svc.best_score_ \n",
    "print mod_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4 6 7]\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_final_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/anaconda2/lib/python2.7/site-packages/sklearn/calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/home/nlp/anaconda2/lib/python2.7/site-packages/sklearn/calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/home/nlp/anaconda2/lib/python2.7/site-packages/sklearn/calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n"
     ]
    }
   ],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True, \n",
    "                              kernel=mod_svc.best_params_['estimator__kernel'], \n",
    "                              C=mod_svc.best_params_['estimator__C'], \n",
    "                              degree=mod_svc.best_params_['estimator__degree']))\n",
    "\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "## Calibrate prob\n",
    "sig_clf_svc = CalibratedClassifierCV(clf_svc, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "\n",
    "sig_clf_svc_probs = sig_clf_svc.predict_proba(test_vectors)\n",
    "\n",
    "\n",
    "# Manual Calibration\n",
    "clf_svc_probs = clf_svc.predict_proba(test_vectors)\n",
    "\n",
    "class_max_prob_lists = np.array([max(clf_svc_probs[:,val]) for val in range(len(clf_svc_probs[0]))])\n",
    "class_min_prob_lists = np.array([min(clf_svc_probs[:,val]) for val in range(len(clf_svc_probs[0]))])\n",
    "delta = class_max_prob_lists - class_min_prob_lists\n",
    "\n",
    "\n",
    "# Normalized for test vector\n",
    "scaled_calib_svc_probs = np.divide(clf_svc_probs,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1da5c490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(scaled_calib_svc_probs, axis = 1)\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4 6 7]\n",
      "[1 3 4 6 7]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       194\n",
      "          1       0.26      0.64      0.37       206\n",
      "          2       0.00      0.00      0.00       199\n",
      "          3       0.38      0.74      0.51       187\n",
      "          4       0.36      0.48      0.41       192\n",
      "          5       0.00      0.00      0.00       200\n",
      "          6       0.31      0.39      0.35       160\n",
      "          7       0.55      0.55      0.55       211\n",
      "\n",
      "avg / total       0.23      0.35      0.27      1549\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       194\n",
      "          1       0.27      0.51      0.36       206\n",
      "          2       0.00      0.00      0.00       199\n",
      "          3       0.48      0.70      0.57       187\n",
      "          4       0.30      0.51      0.38       192\n",
      "          5       0.00      0.00      0.00       200\n",
      "          6       0.26      0.41      0.32       160\n",
      "          7       0.40      0.61      0.48       211\n",
      "\n",
      "avg / total       0.21      0.34      0.26      1549\n",
      "\n",
      "0.349903163331\n",
      "0.340219496449\n"
     ]
    }
   ],
   "source": [
    "preds1 = clf_svc.predict(test_vectors)\n",
    "preds2 = sig_clf_svc.predict(test_vectors)\n",
    "print np.unique(preds1)\n",
    "print np.unique(preds2)\n",
    "print classification_report(test_labels,preds1)\n",
    "print classification_report(test_labels,preds2)\n",
    "print accuracy_score(test_labels,preds1)\n",
    "print accuracy_score(test_labels,preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the new class, we select a Percentile for Probability Threshold for Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prob_percentile_85 = np.array([np.percentile(scaled_calib_svc_probs[:,val], 85.0) \n",
    "                                     for val in range(len(scaled_calib_svc_probs[0]))])\n",
    "\n",
    "test_class_preds = np.greater_equal(scaled_calib_svc_probs,class_prob_percentile_85).astype(int)\n",
    "\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "valid_class_probs = np.multiply(scaled_calib_svc_probs, test_class_preds)\n",
    "valid_class = np.greater_equal(np.ceil(valid_class_probs),1).astype(int)\n",
    "predicted_multinomial = np.multiply(valid_class, np.unique(train_final_labels))\n",
    "predicted_test_class = np.max(predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted test classes [0 1 3 4 6 7]\n",
      "train labels [1 3 4 6 7]\n",
      "Full list of original test labels [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print \"predicted test classes\", np.unique(predicted_test_class)\n",
    "print \"train labels\", np.unique(train_final_labels)\n",
    "print \"Full list of original test labels\", np.unique(orig_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "orig_valid_labels = copy.copy(valid_final_labels)\n",
    "\n",
    "missing_class_idx_test = np.where(np.isin(test_labels, missing_class))[0]\n",
    "missing_class_idx_val = np.where(np.isin(valid_final_labels, missing_class))[0]\n",
    "\n",
    "#print missing_class_idx_test\n",
    "#orig_test_labels = copy.copy(test_labels)\n",
    "for i in range(len(test_labels)): \n",
    "    if i in missing_class_idx_test:\n",
    "        test_labels[i] = 0\n",
    "        \n",
    "for i in range(len(valid_final_labels)): \n",
    "    if i in missing_class_idx_val:\n",
    "        valid_final_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.39      0.44       593\n",
      "          1       0.35      0.39      0.37       206\n",
      "          3       0.55      0.66      0.60       187\n",
      "          4       0.40      0.42      0.41       192\n",
      "          6       0.30      0.39      0.34       160\n",
      "          7       0.52      0.57      0.55       211\n",
      "\n",
      "avg / total       0.46      0.45      0.45      1549\n",
      "\n",
      "0.450613298903\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, predicted_test_class)\n",
    "print accuracy_score(test_labels, predicted_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230 133   0  71  62   0  58  39]\n",
      "593\n",
      "230.0 593\n",
      "0.387858347386\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(sorted(predicted_test_class[unseen_class_indices]))\n",
    "print sum(np.bincount(sorted(predicted_test_class[unseen_class_indices])))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0]), \\\n",
    "    sum(np.isin(test_labels, missing_class).astype(int))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0])/sum(np.isin(test_labels, \\\n",
    "                                                                                            missing_class).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3103, 450)\n",
      "(1239, 450)\n",
      "(1549, 450)\n",
      "Size of the train dataframe: (3103, 451)\n",
      "Size of the test dataframe: (1239, 451)\n",
      "Size of the test dataframe: (1549, 451)\n",
      "3103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_final_vectors = np.array(train_final_vectors)\n",
    "valid_final_vectors=np.array(valid_final_vectors)\n",
    "test_vectors=np.array(test_vectors)\n",
    "print train_final_vectors.shape\n",
    "print valid_final_vectors.shape\n",
    "print test_vectors.shape\n",
    "\n",
    "\n",
    "X = train_final_vectors\n",
    "y = train_final_labels\n",
    "\n",
    "X_val = valid_final_vectors\n",
    "y_val = valid_final_labels\n",
    "\n",
    "X_test = test_vectors\n",
    "y_test = test_labels\n",
    "\n",
    "feat_cols = [ 'col'+str(i) for i in range(X.shape[1]) ]\n",
    "feat_cols_val = [ 'col'+str(i) for i in range(X_val.shape[1]) ]\n",
    "feat_cols_test = [ 'col'+str(i) for i in range(X_test.shape[1]) ]\n",
    "\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['label'] = y\n",
    "df['label'] = df['label'].apply(lambda i: str(i))\n",
    "\n",
    "\n",
    "df_val = pd.DataFrame(X_val,columns=feat_cols_val)\n",
    "df_val['label'] = y_val\n",
    "df_val['label'] = df_val['label'].apply(lambda i: str(i))\n",
    "\n",
    "df_test = pd.DataFrame(X_test,columns=feat_cols_test)\n",
    "df_test['label'] = y_test\n",
    "df_test['label'] = df_test['label'].apply(lambda i: str(i))\n",
    "\n",
    "\n",
    "X, y = None, None\n",
    "print 'Size of the train dataframe: {}'.format(df.shape)\n",
    "print 'Size of the test dataframe: {}'.format(df_val.shape)\n",
    "print 'Size of the test dataframe: {}'.format(df_test.shape)\n",
    "\n",
    "N = df.shape[0]\n",
    "print N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Semantic Analysis for dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 0.093847s\n",
      "Explained variance of the SVD step: 69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "t0 = time()\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "lsa_result = lsa.fit_transform(df[feat_cols].values)\n",
    "lsa_val = lsa.fit_transform(df_val[feat_cols].values)\n",
    "lsa_test = lsa.transform(df_test[feat_cols_test].values)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also try PCA for dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [ 0.27525303  0.08254317  0.05819358  0.04140088  0.03538666  0.02235701\n",
      "  0.02126207  0.0201448   0.01669327  0.01542604  0.01392297  0.013236\n",
      "  0.01234412  0.0122098   0.01079311  0.01034703  0.00940974  0.00893931\n",
      "  0.00850701  0.00797225]\n",
      "Explained variation All components: 0.696341861039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "#df['pca-three'] = pca_result[:,2]\n",
    "#df['pca-four'] = pca_result[:,3]\n",
    "#df['pca-five'] = pca_result[:,4]\n",
    "\n",
    "\n",
    "print 'Explained variation per principal component: {}'.format(pca.explained_variance_ratio_)\n",
    "print 'Explained variation All components: {}'.format(sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We will use LCA as it capture higher percentage of variation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models\n",
    "\n",
    "### Fit Gaussian Mixture Models of varying components and covariance matrix sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "\n",
    "from sklearn import mixture\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "def GMM_fits(input_data=lsa_result, max_comp=21):\n",
    "    # Number of samples per component\n",
    "    n_samples = N\n",
    "    # Generate random sample, two components\n",
    "    np.random.seed(0)\n",
    "    X = np.array(input_data)\n",
    "    #X=np.array(pca_result_5)\n",
    "    print X.shape\n",
    "\n",
    "    bic_2 = {}\n",
    "    n_components_range = range(max_comp, max_comp+1)\n",
    "    cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "    aic_dict = {}\n",
    "    bic_dict = {}\n",
    "    lowest_bic = np.infty\n",
    "    lowest_aic = np.infty\n",
    "\n",
    "    for cv_type in cv_types:\n",
    "\n",
    "        bic = []\n",
    "        aic = []\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a Gaussian mixture with EM\n",
    "            gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                          covariance_type=cv_type, \n",
    "                                          reg_covar =1e-3,\n",
    "                                          random_state=0, \n",
    "                                          init_params='kmeans',\n",
    "                                          max_iter = 1350)\n",
    "            gmm.fit(X)\n",
    "            bic.append(gmm.bic(X))\n",
    "            aic.append(gmm.aic(X))\n",
    "            bic_2[cv_type+\"-\" + str(n_components)] = gmm.bic(X)\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "            if aic[-1] < lowest_aic:\n",
    "                lowest_aic = aic[-1]\n",
    "\n",
    "        aic_dict[cv_type] = aic\n",
    "        bic_dict[cv_type] = bic\n",
    "\n",
    "    clf = best_gmm\n",
    "    sorted_bic_2 = sorted(bic_2.items(), key=operator.itemgetter(1))\n",
    "    return clf, bic_dict, aic_dict, sorted_bic_2, lowest_bic, lowest_aic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Plot AIC/BIC for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_selection_criteria(best_model, aic_dict, bic_dict, information_criteria = 'bic', max_comp = 21):\n",
    "    n_components_range = range(1,max_comp)\n",
    "    if information_criteria == 'bic':\n",
    "        for cv in bic_dict.keys():\n",
    "            plt.plot(n_components_range, bic_dict[cv], label=str(cv))\n",
    "            #plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "            plt.legend(loc=cv)\n",
    "            plt.xlabel('n_components_range')\n",
    "        plt.title(\"BIC plot\")\n",
    "    else:\n",
    "        for cv in aic_dict.keys():\n",
    "            plt.plot(n_components_range, aic_dict[cv], label=str(cv))\n",
    "            #plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "            plt.legend(loc=cv)\n",
    "            plt.xlabel('n_components_range')\n",
    "        plt.title(\"AIC plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3103, 20)\n"
     ]
    }
   ],
   "source": [
    "num_train_class = 5\n",
    "num_unseen_class =3\n",
    "best_lsa_model,lsa_bic_d,lsa_aic_d,sorted_lsa_bic,lowest_lsa_aic,lowest_lsa_bic = GMM_fits(input_data=lsa_result, \n",
    "                                                                                            max_comp=num_train_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the lowest AIC/BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest_BIC -107346.606156\n",
      "Lowest_AIC -100376.302294\n",
      "Best GMM Model Parameters based on BIC <bound method GaussianMixture.get_params of GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=1350,\n",
      "        means_init=None, n_components=5, n_init=1, precisions_init=None,\n",
      "        random_state=0, reg_covar=0.001, tol=0.001, verbose=0,\n",
      "        verbose_interval=10, warm_start=False, weights_init=None)>\n"
     ]
    }
   ],
   "source": [
    "print \"Lowest_BIC\", lowest_lsa_bic\n",
    "print \"Lowest_AIC\", lowest_lsa_aic  \n",
    "print \"Best GMM Model Parameters based on BIC\", best_lsa_model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction using the lowest BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.154\n",
      "Completeness: 0.157\n",
      "V-measure: 0.156\n",
      "Adjusted Rand-Index: 0.126\n",
      "Silhouette Coefficient: 0.069\n",
      "fowlkes_mallows_score: 0.307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 467.,    0.,  591.,    0.,    0.,  927.,    0.,  540.,    0.,  578.]),\n",
       " array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e89335d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_cluster = best_lsa_model.predict(lsa_result)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df['label'], predicted_cluster))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df['label'], predicted_cluster))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df['label'], predicted_cluster))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df['label'], predicted_cluster))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_result, predicted_cluster, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df['label'], predicted_cluster))\n",
    "plt.hist(predicted_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_comp(predicted_labels,actual_labels):\n",
    "    Cluster_ids = {}\n",
    "    for i in predicted_labels:\n",
    "        Cluster_ids[i] = (predicted_labels==i).nonzero()[0]\n",
    "\n",
    "    targets = np.array(actual_labels)\n",
    "    #print Cluster_ids\n",
    "    for label in Cluster_ids.keys():\n",
    "        #print type(label)\n",
    "        idx = Cluster_ids[label]\n",
    "        print \"Cluster Number\", str(label), \"Composition\", np.bincount(targets[idx])\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Number 0 Composition [  0  15   0  23 158   0  95 176]\n",
      "\n",
      "\n",
      "Cluster Number 1 Composition [  0 319   0  43 100   0  90  39]\n",
      "\n",
      "\n",
      "Cluster Number 2 Composition [  0 181   0 110 243   0 243 150]\n",
      "\n",
      "\n",
      "Cluster Number 3 Composition [  0  30   0  85  76   0 151 198]\n",
      "\n",
      "\n",
      "Cluster Number 4 Composition [  0  78   0 389  54   0  37  20]\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print print_cluster_comp(predicted_labels=predicted_cluster, actual_labels=train_final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_val_labels = best_lsa_model.predict_proba(lsa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.89144507e-71   8.58728751e-06   4.95373851e-75   9.99991413e-01\n",
      "    6.17593096e-51]\n",
      " [  1.27113047e-14   9.99982906e-01   4.02476343e-18   2.49846411e-09\n",
      "    1.70914890e-05]\n",
      " [  4.88311516e-03   9.83287503e-01   1.60684576e-07   1.17003123e-02\n",
      "    1.28909165e-04]\n",
      " ..., \n",
      " [  2.29214498e-18   1.00000000e+00   1.83838224e-26   2.69227187e-14\n",
      "    1.99240218e-11]\n",
      " [  9.99999962e-01   2.90570209e-23   3.81488888e-08   2.75605742e-31\n",
      "    1.88182700e-20]\n",
      " [  1.77146484e-07   9.75725300e-02   2.06645480e-12   5.89161658e-01\n",
      "    3.13265635e-01]]\n",
      "[ 0.99999996  1.          1.          1.          1.        ]\n",
      "[[  2.89144518e-71   8.58728751e-06   4.95373852e-75   9.99991413e-01\n",
      "    6.17593096e-51]\n",
      " [  1.27113052e-14   9.99982906e-01   4.02476344e-18   2.49846411e-09\n",
      "    1.70914890e-05]\n",
      " [  4.88311534e-03   9.83287503e-01   1.60684577e-07   1.17003123e-02\n",
      "    1.28909165e-04]\n",
      " ..., \n",
      " [  2.29214507e-18   1.00000000e+00   1.83838224e-26   2.69227187e-14\n",
      "    1.99240218e-11]\n",
      " [  1.00000000e+00   2.90570209e-23   3.81488889e-08   2.75605742e-31\n",
      "    1.88182700e-20]\n",
      " [  1.77146490e-07   9.75725300e-02   2.06645481e-12   5.89161658e-01\n",
      "    3.13265635e-01]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_val_labels\n",
    "val_gmm_class_max_prob_lists = np.array([max(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_class_min_prob_lists = np.array([min(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_delta = val_gmm_class_max_prob_lists - val_gmm_class_min_prob_lists\n",
    "\n",
    "print val_gmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_gmm_val_class_probs = np.divide(pred_proba_val_labels,val_gmm_delta)\n",
    "print scaled_gmm_val_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e89189350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_val_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00956492  0.99945471  0.00102168  0.99967839  0.3318508 ]\n",
      "[[  2.89144518e-71   8.58728751e-06   4.95373852e-75   9.99991413e-01\n",
      "    6.17593096e-51]\n",
      " [  1.27113052e-14   9.99982906e-01   4.02476344e-18   2.49846411e-09\n",
      "    1.70914890e-05]\n",
      " [  4.88311534e-03   9.83287503e-01   1.60684577e-07   1.17003123e-02\n",
      "    1.28909165e-04]\n",
      " ..., \n",
      " [  2.29214507e-18   1.00000000e+00   1.83838224e-26   2.69227187e-14\n",
      "    1.99240218e-11]\n",
      " [  1.00000000e+00   2.90570209e-23   3.81488889e-08   2.75605742e-31\n",
      "    1.88182700e-20]\n",
      " [  1.77146490e-07   9.75725300e-02   2.06645481e-12   5.89161658e-01\n",
      "    3.13265635e-01]]\n",
      "[[0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " ..., \n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[ 0  1  3  4  5  6  7  8 11 12]\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 85.0\n",
    "val_gmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_gmm_val_class_probs[:,val], class_threshold) \n",
    "                                     for val in range(len(scaled_gmm_val_class_probs[0]))])\n",
    "\n",
    "print val_gmm_class_prob_percentile_cutoff\n",
    "\n",
    "gmm_val_class_preds = np.greater_equal(scaled_gmm_val_class_probs,val_gmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "print scaled_gmm_val_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "val_gmm_valid_class_probs = np.multiply(scaled_gmm_val_class_probs, gmm_val_class_preds)\n",
    "val_gmm_valid_class = np.greater_equal(np.ceil(val_gmm_valid_class_probs),1).astype(int)\n",
    "print val_gmm_valid_class\n",
    "val_gmm_predicted_multinomial = np.multiply(val_gmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(val_gmm_predicted_multinomial, axis=1))\n",
    "gmm_predicted_val_class = np.max(val_gmm_predicted_multinomial,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487 153   0 151 168   0 134 146] [424 115   0 186 142   0 186 186]\n",
      "1239 1239\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(valid_final_labels), np.bincount(gmm_predicted_val_class)\n",
    "print np.sum(np.bincount(valid_final_labels)), np.sum(np.bincount(gmm_predicted_val_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Unseen Class Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composition of gmm_predicted_valid_class for true unseen class indices [156  60   0  50  84   0  78  59]\n",
      "487\n"
     ]
    }
   ],
   "source": [
    "print \"Composition of gmm_predicted_valid_class for true unseen class indices\", np.bincount(sorted(gmm_predicted_val_class[missing_class_idx_val]))\n",
    "print sum(np.bincount(sorted(gmm_predicted_val_class[missing_class_idx_val])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.37      0.34       424\n",
      "          1       0.12      0.16      0.13       115\n",
      "          3       0.08      0.06      0.07       186\n",
      "          4       0.11      0.13      0.12       142\n",
      "          6       0.11      0.08      0.09       186\n",
      "          7       0.13      0.10      0.11       186\n",
      "\n",
      "avg / total       0.18      0.19      0.19      1239\n",
      "\n",
      "[[156  64  42  66  47  49]\n",
      " [ 60  18   4  11  11  11]\n",
      " [ 50  13  12  45  20  46]\n",
      " [ 84  13   6  19  13   7]\n",
      " [ 78  30  41   8  15  14]\n",
      " [ 59  15  46  19  28  19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "print classification_report(gmm_predicted_val_class, valid_final_labels)\n",
    "print confusion_matrix(gmm_predicted_val_class, valid_final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.367924528302 0.320328542094 0.34248079034\n"
     ]
    }
   ],
   "source": [
    "def calculate_unseen_class_f1score(pred_class, true_class, unseen_class_id):\n",
    "    predicted_zero_ind = (pred_class==unseen_class_id).nonzero()[0]\n",
    "    predicted_nonzero_ind = (pred_class > unseen_class_id).nonzero()[0]\n",
    "    #print np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    TP = np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    FP =  sum(np.bincount(true_class[predicted_zero_ind])) - TP\n",
    "    FN =  np.bincount(true_class[predicted_nonzero_ind])[0]\n",
    "    #print TP, FP, FN\n",
    "    unseen_class_precision = float(TP)/(TP+FP)\n",
    "    unseen_class_recall = float(TP)/(TP+FN)\n",
    "    unseen_class_f1 = 2*unseen_class_precision*unseen_class_recall/(unseen_class_precision+unseen_class_recall)\n",
    "    #print unseen_class_precision,unseen_class_recall,unseen_class_f1\n",
    "    return unseen_class_precision, unseen_class_recall,unseen_class_f1\n",
    "    \n",
    "pr,re,f1 = calculate_unseen_class_f1score(gmm_predicted_val_class, np.array(valid_final_labels), 0)\n",
    "print pr,re,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  65 F1 Score:  0.00813008130081\n",
      "Actual Unseen Class 487 Predicted Unseen Class 5\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  66 F1 Score:  0.0160320641283\n",
      "Actual Unseen Class 487 Predicted Unseen Class 12\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  67 F1 Score:  0.0276679841897\n",
      "Actual Unseen Class 487 Predicted Unseen Class 19\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  68 F1 Score:  0.03515625\n",
      "Actual Unseen Class 487 Predicted Unseen Class 25\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  69 F1 Score:  0.0419847328244\n",
      "Actual Unseen Class 487 Predicted Unseen Class 37\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  70 F1 Score:  0.0597014925373\n",
      "Actual Unseen Class 487 Predicted Unseen Class 49\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  71 F1 Score:  0.0798548094374\n",
      "Actual Unseen Class 487 Predicted Unseen Class 64\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  72 F1 Score:  0.0886524822695\n",
      "Actual Unseen Class 487 Predicted Unseen Class 77\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  73 F1 Score:  0.0939130434783\n",
      "Actual Unseen Class 487 Predicted Unseen Class 88\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  74 F1 Score:  0.108658743633\n",
      "Actual Unseen Class 487 Predicted Unseen Class 102\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  75 F1 Score:  0.117056856187\n",
      "Actual Unseen Class 487 Predicted Unseen Class 111\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  76 F1 Score:  0.151857835218\n",
      "Actual Unseen Class 487 Predicted Unseen Class 132\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  77 F1 Score:  0.179566563467\n",
      "Actual Unseen Class 487 Predicted Unseen Class 159\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  78 F1 Score:  0.201201201201\n",
      "Actual Unseen Class 487 Predicted Unseen Class 179\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  79 F1 Score:  0.230215827338\n",
      "Actual Unseen Class 487 Predicted Unseen Class 208\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  80 F1 Score:  0.239221140473\n",
      "Actual Unseen Class 487 Predicted Unseen Class 232\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  81 F1 Score:  0.256341789052\n",
      "Actual Unseen Class 487 Predicted Unseen Class 262\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  82 F1 Score:  0.267175572519\n",
      "Actual Unseen Class 487 Predicted Unseen Class 299\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  83 F1 Score:  0.284671532847\n",
      "Actual Unseen Class 487 Predicted Unseen Class 335\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  84 F1 Score:  0.305202312139\n",
      "Actual Unseen Class 487 Predicted Unseen Class 378\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  85 F1 Score:  0.34248079034\n",
      "Actual Unseen Class 487 Predicted Unseen Class 424\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  86 F1 Score:  0.349738219895\n",
      "Actual Unseen Class 487 Predicted Unseen Class 468\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  87 F1 Score:  0.355289421158\n",
      "Actual Unseen Class 487 Predicted Unseen Class 515\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  88 F1 Score:  0.380861244019\n",
      "Actual Unseen Class 487 Predicted Unseen Class 558\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  89 F1 Score:  0.394495412844\n",
      "Actual Unseen Class 487 Predicted Unseen Class 603\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  90 F1 Score:  0.422066549912\n",
      "Actual Unseen Class 487 Predicted Unseen Class 655\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  91 F1 Score:  0.438079191238\n",
      "Actual Unseen Class 487 Predicted Unseen Class 700\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  92 F1 Score:  0.45718901454\n",
      "Actual Unseen Class 487 Predicted Unseen Class 751\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  93 F1 Score:  0.474497681607\n",
      "Actual Unseen Class 487 Predicted Unseen Class 807\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  94 F1 Score:  0.490007401925\n",
      "Actual Unseen Class 487 Predicted Unseen Class 864\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 0.0\n",
    "best_f1_score=0.0\n",
    "for threshold in range(50,95):\n",
    "    try:\n",
    "        val_gmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_gmm_val_class_probs[:,val], float(threshold)) \n",
    "                                             for val in range(len(scaled_gmm_val_class_probs[0]))])\n",
    "\n",
    "        #print val_gmm_class_prob_percentile_cutoff\n",
    "\n",
    "        gmm_val_class_preds = np.greater_equal(scaled_gmm_val_class_probs,val_gmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "        #print scaled_gmm_val_class_probs\n",
    "        # Predict the test label based on percental\n",
    "        # If a data is below 80% for prob of all class, it belongs to open class\n",
    "        val_gmm_valid_class_probs_dup = np.multiply(scaled_gmm_val_class_probs, gmm_val_class_preds)\n",
    "\n",
    "        val_gmm_valid_class_max_probs = np.max(val_gmm_valid_class_probs_dup, axis=1)\n",
    "        #print gmm_valid_class_max_probs\n",
    "        #print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "        val_temp = np.equal(val_gmm_valid_class_probs_dup , val_gmm_valid_class_max_probs.reshape(len(val_gmm_valid_class_max_probs),1))\n",
    "        val_gmm_valid_class_probs=np.multiply(val_gmm_valid_class_probs_dup,val_temp)\n",
    "        val_gmm_valid_class = np.greater_equal(np.ceil(val_gmm_valid_class_probs),1).astype(int)\n",
    "        #print val_gmm_valid_class\n",
    "        val_gmm_predicted_multinomial = np.multiply(val_gmm_valid_class, np.unique(train_final_labels))\n",
    "        #print np.unique(np.sum(val_gmm_predicted_multinomial, axis=1))\n",
    "        gmm_predicted_val_class = np.max(val_gmm_predicted_multinomial,axis=1)  \n",
    "        print np.unique(gmm_predicted_val_class), np.unique(valid_final_labels)\n",
    "        pr,re,f1 = calculate_unseen_class_f1score(gmm_predicted_val_class,valid_final_labels,0)\n",
    "        print \"Threshold: \",threshold, \"F1 Score: \", f1 \n",
    "        print \"Actual Unseen Class\", np.bincount(valid_final_labels)[0], \"Predicted Unseen Class\",np.bincount(gmm_predicted_val_class)[0]\n",
    "        # Set the threshold so that not unseen class volume is actual unseen class volume in validation set\n",
    "        unseen_class_ratio = float(np.bincount(gmm_predicted_val_class)[0])/np.bincount(valid_final_labels)[0]\n",
    "        #overall_F1_score = f1_score(gmm_predicted_val_class, valid_final_labels)\n",
    "        if f1 > best_f1_score and unseen_class_ratio < 1.1:\n",
    "\n",
    "            best_f1_score = f1\n",
    "            best_threshold = threshold\n",
    "    except:\n",
    "        print \"Threshold Too Low. No unseen class prediction\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test_labels = best_lsa_model.predict_proba(lsa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.09108802e-35   9.99999353e-01   4.95334985e-38   6.46567585e-07\n",
      "    4.65011564e-25]\n",
      " [  5.01280960e-71   1.03909076e-04   1.37801071e-73   9.99896091e-01\n",
      "    6.63194436e-50]\n",
      " [  5.25121773e-15   1.55848388e-10   1.00000000e+00   1.59708914e-22\n",
      "    1.22478012e-10]\n",
      " ..., \n",
      " [  1.25886232e-22   9.99965171e-01   2.85706149e-24   3.48292372e-05\n",
      "    2.32028912e-15]\n",
      " [  9.99999962e-01   2.90570209e-23   3.81488888e-08   2.75605742e-31\n",
      "    1.88182700e-20]\n",
      " [  2.01522419e-48   4.17769922e-08   4.28116259e-45   9.99999958e-01\n",
      "    2.77892098e-27]]\n",
      "[ 0.99999999  1.          1.          1.          1.        ]\n",
      "[[  1.09108803e-35   9.99999353e-01   4.95334985e-38   6.46567585e-07\n",
      "    4.65011564e-25]\n",
      " [  5.01280964e-71   1.03909076e-04   1.37801071e-73   9.99896091e-01\n",
      "    6.63194436e-50]\n",
      " [  5.25121778e-15   1.55848388e-10   1.00000000e+00   1.59708914e-22\n",
      "    1.22478012e-10]\n",
      " ..., \n",
      " [  1.25886233e-22   9.99965171e-01   2.85706149e-24   3.48292372e-05\n",
      "    2.32028912e-15]\n",
      " [  9.99999971e-01   2.90570209e-23   3.81488888e-08   2.75605742e-31\n",
      "    1.88182700e-20]\n",
      " [  2.01522421e-48   4.17769922e-08   4.28116259e-45   9.99999958e-01\n",
      "    2.77892098e-27]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_test_labels\n",
    "gmm_class_max_prob_lists = np.array([max(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "gmm_class_min_prob_lists = np.array([min(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "gmm_delta = gmm_class_max_prob_lists - gmm_class_min_prob_lists\n",
    "\n",
    "print gmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_gmm_test_class_probs = np.divide(pred_proba_test_labels,gmm_delta)\n",
    "print scaled_gmm_test_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1ee32390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_test_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "[[ 0.          0.99999935  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.99989609  0.        ]\n",
      " [ 0.          0.          1.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.99996517  0.          0.          0.        ]\n",
      " [ 0.99999997  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.99999996  0.        ]]\n",
      "[ 0.99999935  0.99989609  1.         ...,  0.99996517  0.99999997\n",
      "  0.99999996]\n",
      "[[0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " ..., \n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]]\n",
      "[0 1 3 4 6 7]\n"
     ]
    }
   ],
   "source": [
    "print best_threshold\n",
    "gmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_gmm_test_class_probs[:,val], best_threshold) \n",
    "                                     for val in range(len(scaled_gmm_test_class_probs[0]))])\n",
    "\n",
    "#print gmm_class_prob_percentile_cutoff\n",
    "\n",
    "gmm_test_class_preds = np.greater_equal(scaled_gmm_test_class_probs,gmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "#print scaled_gmm_test_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "gmm_valid_class_probs_dup = np.multiply(scaled_gmm_test_class_probs, gmm_test_class_preds)\n",
    "print gmm_valid_class_probs_dup\n",
    "gmm_valid_class_max_probs = np.max(gmm_valid_class_probs_dup, axis=1)\n",
    "print gmm_valid_class_max_probs\n",
    "#print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "temp = np.equal(gmm_valid_class_probs_dup , gmm_valid_class_max_probs.reshape(len(gmm_valid_class_max_probs),1))\n",
    "gmm_valid_class_probs=np.multiply(gmm_valid_class_probs_dup,temp)\n",
    "gmm_valid_class = np.greater_equal(np.ceil(gmm_valid_class_probs),1).astype(int)\n",
    "print gmm_valid_class\n",
    "gmm_predicted_multinomial = np.multiply(gmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(gmm_predicted_multinomial, axis=1))\n",
    "gmm_predicted_test_class = np.max(gmm_predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "#unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[593 206   0 187 192   0 160 211] [638 170   0 202 135   0 202 202]\n",
      "1549 1549\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(test_labels), np.bincount(gmm_predicted_test_class)\n",
    "print np.sum(np.bincount(test_labels)), np.sum(np.bincount(gmm_predicted_test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  80  56  72  84  62]\n",
      " [ 75  33  15  23  28  32]\n",
      " [ 68   8  13   6  45  47]\n",
      " [ 90  22  41  16  14   9]\n",
      " [ 84  14  18   9  13  22]\n",
      " [ 82  13  59   9  18  30]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(test_labels, gmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.37      0.40      0.39       593\n",
      "          1       0.19      0.16      0.18       206\n",
      "          3       0.06      0.07      0.07       187\n",
      "          4       0.12      0.08      0.10       192\n",
      "          6       0.06      0.08      0.07       160\n",
      "          7       0.15      0.14      0.15       211\n",
      "\n",
      "avg / total       0.22      0.22      0.22      1549\n",
      "\n",
      "0.222078760491\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, gmm_predicted_test_class)\n",
    "print accuracy_score(test_labels, gmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Class Precision, Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Class Precision:  0.37460815047\n",
      "Unseen Class Recall:  0.403035413153\n",
      "Unseen Class F1 Score:  0.388302193339\n"
     ]
    }
   ],
   "source": [
    "print \"Unseen Class Precision: \", calculate_unseen_class_f1score(gmm_predicted_test_class,test_labels,0)[0]\n",
    "print \"Unseen Class Recall: \", calculate_unseen_class_f1score(gmm_predicted_test_class,test_labels,0)[1]\n",
    "print \"Unseen Class F1 Score: \", calculate_unseen_class_f1score(gmm_predicted_test_class,test_labels,0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_indices = (gmm_predicted_test_class==0).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.034\n",
      "Completeness: 0.035\n",
      "V-measure: 0.034\n",
      "Adjusted Rand-Index: 0.005\n",
      "Silhouette Coefficient: 0.007\n",
      "fowlkes_mallows_score: 0.235\n"
     ]
    }
   ],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_test, gmm_predicted_test_class, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df_test['label'], gmm_predicted_test_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Clustering Unsee Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_unseen_class_lsa= lsa_test[pred_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.355\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1f4cfa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.355\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e89b4bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.355\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1f814fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.355\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGLFJREFUeJzt3HuYXVV9xvHvS8aAxUACmWDIhbGSqlDLpVMIj1UQ0AK2hrbEYmkTMDVVqZcHb6nSVmsvULVRa4tNje2EqhBRmohUjOFisSZ0UigVomaIkIwJySBJJEa06K9/7DW6OTkzZ0/mnDOZlffzPPOcvddaZ++19j7znn3WuSgiMDOzfB021h0wM7PWctCbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQT+OSOqSFJI6KrS9XNLdo9zfiyV9sxn9OdhIukzSl8a6HzlpxmOuZntNOUfpMXpiM/o0XjnoW0TSw5J+JGlqTfl96YHXNTY9qy4i/iMinje4nsZ0/mi2KekMSbdK2i3pcUn3SLpi9L0dmYj4ZES8vN37Hcp4ftJslYPtHI1nDvrW+jbw6sEVSS8Enjl23Rlbks4CbgfuAk4EjgVeD1zY5n44TA9yPkfN5aBvreuBBaX1hcCKcgNJR0taIWlA0iOSrpZ0WKqbIOkDkh6TtBl4RZ37Lpe0XdJ3JP2FpAmNOiWpR9Jb0/KMdCX5hrR+YrrSlqRzJPWn8uuB2cDnJe2V9I7SJi+TtCX1893D7Pr9QE9EXBsRj0VhQ0S8qtS310rqS31YLen4VP4xSR+oGccqSVel5SWSHpL0hKQHJf1mqd3lkr4qaamkx4H31E4zSPqwpK2Svidpg6QXl+reI2llOk9PSHpAUnepfpakz6Vz+F1JHy3VvUbSRkm7JN0m6YQhjs1X0u3udHzPTsfghaVtTZP0A0mdg+dG0rvScX9Y0mWltoenx84WSTvS8at0kZEeA3dJ2pO2fWOpLiS9SdLmVPf+wcdrqc0H0ni/LenCUvmQj9eK5+hkSWvScdkh6V2p/AxJX1PxKnG7pI9KmlhlrIeMiPBfC/6Ah4HzgW8CLwAmAFuBE4AAulK7FcAqYBLQBXwLWJTqXgd8A5gFHAPcke7bker/DfhH4EhgGnAP8Iep7nLg7iH69hrg82n5d4GHgBtLdavS8jlAf+2YSutdqT//RPFK5RTgh8AL6uzz54AfAy8d5pidCzwGnA4cDvwd8JVU95J0/JTWpwA/AI5P6/OB4ykuXn4H+D4wvXQsngLeCHSkvj7t+AC/R/EKowN4K/AocESqew/wJHBROo9/DaxLdROA/wGWpvNwBPCrqe5ioC+d/w7gauA/hxj74LHsKJX9A3Btaf3NpfN2ThrT36ZjdXYa8/NS/YeA1RSPm0nA54G/Lm1r92A/6/Tl08C707E8otwu9fGOtN3ZFI/XPygd5/8DXpuOy+uBbaVz1ujxOuQ5SmPYns7NEWn9zFT3y8DcdL8uYCPwlpo+nzjWmTCmeTTWHcj1j58F/dUpGC4A1qQHY6QH5ASKYDypdL8/BO5My7cDryvVvXwwDIDj0n2fWap/NXBHWv7pP0mdvj03/aMfBnws7bM/1fUAV6Xlc6gW9DNLZfcAl9bZ54zU9vnDHLPlwN+U1p+VgqMLELAFeEmqey1w+zDbug+YVzoWW2rqhzw+qX4XcEpafg/w5VLdScAP0vJZwAClgC61+3fSk3ZaPwzYB5xQp+3gsSwH/ZkUT26HpfVe4FWlc/MUcGSp/UrgT9Kx+j7w3FLdWcC3Kz52VwDLyue1VBfABaX1NwBrS8e0r1T3c6n9s6n2eB3yHKW291bs/1uAm2v6fEgHvaduWu96iqvmy6mZtgGmAhOBR0plj1CEIhRXqFtr6gadADwD2J5esu6muFqa1qhDEfEQsBc4FXgxcAuwTdLzKK4M76oysJJHS8v7KAK61i7gJ8D0YbZzPKUxRsRe4LvAjCj+Y2/gZ+95/C7wycG2khaoeKN78Fj8IsXxHVQ+jvuR9NY0xbIn3f/omvvXjvEIFfPIs4BHIuKpOps9AfhwqU+PU4TwjDpt9xMR6ykC+2xJz6d4X2N1qcmuiPh+af0RimPYSRGyG0r7/mIqr+IdqZ/3pGmq19TU1z4mjy+t//Q4RcS+tPgsqj1ehztHsyheee5H0i9IukXSo5K+B/wVTz93hzwHfYtFxCMUb8peBHyupvoxiivW8rztbOA7aXk7xQO8XDdoK8UV0tSImJz+joqIkyt27S7gEmBiRHwnrS+gmBK5b6jhVNz2/ncs/um/Bvz2MM22UToWko6kmE4ZPB6fBi5J89xnAp9N7U6gmD76I+DYiJgMfJ0irBr2Pc3HvxN4FTAl3X9Pzf2HshWYrfpvHm6lmJqYXPp7ZkT8Z522Q/Wvh2Ja6feBmyLiyVLdlHSMBs2mOIaPUUxrnVza79ERUe8JeP+ORDwaEa+NiOMpXu39g57+8cTax+S2Cput8ngd7vG1leKVaD3XUUxxzomIo4B3Ue3cHTIc9O2xCDi35uqLiPgxxcvtv5Q0KQXWVcC/piYrgTdJmilpCrCkdN/twJeAD0o6StJhkp4r6eyKfbqLIhgH3wS8k2J+9O7Ur3p2AD9fcfv1vAO4XNLbJR0LIOkUSTek+k8BV0g6VdLhFFdm6yPiYYCIuJdimuTjwG0RsTvd70iKkBhI27yC4oq+qkkU0yADQIekPwWOqnjfeyiekK+RdKSkIyS9KNV9DPhjSSenfh0taf4Q2xmgeMVTe3yvB36TIuxrXxECvFfSxPRk9evAZyLiJxRPfEslTUv7niHp16oMSNJ8STPT6i6KY1t+TLxd0hRJsyjeN7ixdhu1mvB4vQV4tqS3pDeaJ0k6M9VNAr4H7E2vfF5fcZuHDAd9G0TEQxHRO0T1Gylenm8G7qYIu0+kun8CbqN4s++/2f8VwQKKqZ8HKf4hb2L4qZGyuyj+QQaD/m6Kl/tfGfIexXsNV6eX3m+ruJ+fSley56a/zenTFcuAW1P9Woo55s9ShOdzgUtrNvNpivc+PlXa7oPAByleMewAXgh8dQRdu41iPv1bFFMRT9Jgqqe07x8Dv0ExrbIF6Kd4M5iIuBm4FrghTSl8nSE+Sppe8fwl8NV0fOem8n6Kcx/Af9Tc7VGK876NYhrrdRHxjVT3Too3gtelfX8ZKH8nYq9Knyyq8SvAekl7KaaK3hwR3y7VrwI2ULzy+wLFeytVHPDjNSKeAF5GcawfBTYBL03Vb6OYynuC4n+m4RPPoWbw3XAzO0hJ+gSwLSKuLpWdA/xrRMwc8o6t6UtQTJH0tXO/Njr+UoLZQUzFN6h/CzhtbHti45mnbswOUpLeRzHd8/6aqROzEfHUjZlZ5nxFb2aWuYNijn7q1KnR1dU11t0wMxtXNmzY8FhENPwi3EER9F1dXfT2DvXpQzMzq0fSI41beerGzCx7Dnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzB8U3Y80OVl1LvjBm+374mleM2b4tL76iNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMlcp6CVNlnSTpG9I2ijpLEnHSFojaVO6nZLaStJHJPVJul/S6a0dgpmZDafqFf2HgS9GxPOBU4CNwBJgbUTMAdamdYALgTnpbzFwXVN7bGZmI9Iw6CUdBbwEWA4QET+KiN3APKAnNesBLk7L84AVUVgHTJY0vek9NzOzSqpc0f88MAD8s6R7JX1c0pHAcRGxHSDdTkvtZwBbS/fvT2VPI2mxpF5JvQMDA6MahJmZDa1K0HcApwPXRcRpwPf52TRNPapTFvsVRCyLiO6I6O7s7KzUWTMzG7kqQd8P9EfE+rR+E0Xw7xickkm3O0vtZ5XuPxPY1pzumpnZSDUM+oh4FNgq6Xmp6DzgQWA1sDCVLQRWpeXVwIL06Zu5wJ7BKR4zM2u/qr9H/0bgk5ImApuBKyieJFZKWgRsAeantrcCFwF9wL7U1szMxkiloI+I+4DuOlXn1WkbwJWj7JeZmTWJvxlrZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmasU9JIelvS/ku6T1JvKjpG0RtKmdDsllUvSRyT1Sbpf0umtHICZmQ1vJFf0L42IUyOiO60vAdZGxBxgbVoHuBCYk/4WA9c1q7NmZjZyo5m6mQf0pOUe4OJS+YoorAMmS5o+iv2YmdkoVA36AL4kaYOkxansuIjYDpBup6XyGcDW0n37U5mZmY2BjortXhQR2yRNA9ZI+sYwbVWnLPZrVDxhLAaYPXt2xW6YmdlIVbqij4ht6XYncDNwBrBjcEom3e5MzfuBWaW7zwS21dnmsojojojuzs7OAx+BmZkNq2HQSzpS0qTBZeDlwNeB1cDC1GwhsCotrwYWpE/fzAX2DE7xmJlZ+1WZujkOuFnSYPtPRcQXJf0XsFLSImALMD+1vxW4COgD9gFXNL3XZmZWWcOgj4jNwCl1yr8LnFenPIArm9I7MzMbNX8z1swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy1zloJc0QdK9km5J68+RtF7SJkk3SpqYyg9P632pvqs1XTczsypGckX/ZmBjaf1aYGlEzAF2AYtS+SJgV0ScCCxN7czMbIxUCnpJM4FXAB9P6wLOBW5KTXqAi9PyvLROqj8vtTczszFQ9Yr+Q8A7gJ+k9WOB3RHxVFrvB2ak5RnAVoBUvye1fxpJiyX1SuodGBg4wO6bmVkjDYNe0q8DOyNiQ7m4TtOoUPezgohlEdEdEd2dnZ2VOmtmZiPXUaHNi4BXSroIOAI4iuIKf7KkjnTVPhPYltr3A7OAfkkdwNHA403vuZmZVdLwij4i/jgiZkZEF3ApcHtEXAbcAVySmi0EVqXl1WmdVH97ROx3RW9mZu0xms/RvxO4SlIfxRz88lS+HDg2lV8FLBldF83MbDSqTN38VETcCdyZljcDZ9Rp8yQwvwl9MzOzJvA3Y83MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDYNe0hGS7pH0P5IekPTeVP4cSeslbZJ0o6SJqfzwtN6X6rtaOwQzMxtOlSv6HwLnRsQpwKnABZLmAtcCSyNiDrALWJTaLwJ2RcSJwNLUzszMxkjDoI/C3rT6jPQXwLnATam8B7g4Lc9L66T68ySpaT02M7MRqTRHL2mCpPuAncAa4CFgd0Q8lZr0AzPS8gxgK0Cq3wMcW2ebiyX1SuodGBgY3SjMzGxIlYI+In4cEacCM4EzgBfUa5Zu6129x34FEcsiojsiujs7O6v218zMRmhEn7qJiN3AncBcYLKkjlQ1E9iWlvuBWQCp/mjg8WZ01szMRq7Kp246JU1Oy88Ezgc2AncAl6RmC4FVaXl1WifV3x4R+13Rm5lZe3Q0bsJ0oEfSBIonhpURcYukB4EbJP0FcC+wPLVfDlwvqY/iSv7SFvTbzMwqahj0EXE/cFqd8s0U8/W15U8C85vSOzMzGzV/M9bMLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8tcw6CXNEvSHZI2SnpA0ptT+TGS1kjalG6npHJJ+oikPkn3Szq91YMwM7OhVbmifwp4a0S8AJgLXCnpJGAJsDYi5gBr0zrAhcCc9LcYuK7pvTYzs8oaBn1EbI+I/07LTwAbgRnAPKAnNesBLk7L84AVUVgHTJY0vek9NzOzSkY0Ry+pCzgNWA8cFxHboXgyAKalZjOAraW79aey2m0tltQrqXdgYGDkPTczs0oqB72kZwGfBd4SEd8brmmdstivIGJZRHRHRHdnZ2fVbpiZ2QhVCnpJz6AI+U9GxOdS8Y7BKZl0uzOV9wOzSnefCWxrTnfNzGykqnzqRsByYGNE/G2pajWwMC0vBFaVyhekT9/MBfYMTvGYmVn7dVRo8yLg94H/lXRfKnsXcA2wUtIiYAswP9XdClwE9AH7gCua2mMzMxuRhkEfEXdTf94d4Lw67QO4cpT9MjOzJvE3Y83MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDYNe0ick7ZT09VLZMZLWSNqUbqekckn6iKQ+SfdLOr2VnTczs8aqXNH/C3BBTdkSYG1EzAHWpnWAC4E56W8xcF1zumlmZgeqYdBHxFeAx2uK5wE9abkHuLhUviIK64DJkqY3q7NmZjZyBzpHf1xEbAdIt9NS+Qxga6ldfyrbj6TFknol9Q4MDBxgN8zMrJFmvxmrOmVRr2FELIuI7ojo7uzsbHI3zMxs0IEG/Y7BKZl0uzOV9wOzSu1mAtsOvHtmZjZaBxr0q4GFaXkhsKpUviB9+mYusGdwisfMzMZGR6MGkj4NnANMldQP/BlwDbBS0iJgCzA/Nb8VuAjoA/YBV7Sgz2ZmNgINgz4iXj1E1Xl12gZw5Wg7ZWZmzeNvxpqZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplrSdBLukDSNyX1SVrSin2YmVk1TQ96SROAvwcuBE4CXi3ppGbvx8zMqmnFFf0ZQF9EbI6IHwE3APNasB8zM6ugowXbnAFsLa33A2fWNpK0GFicVvdK+mYL+tJqU4HHxroTbXaojXnMxqtrx2KvwKF3jmH8jvmEKo1aEfSqUxb7FUQsA5a1YP9tI6k3IrrHuh/tdKiN+VAbL3jMOWrF1E0/MKu0PhPY1oL9mJlZBa0I+v8C5kh6jqSJwKXA6hbsx8zMKmj61E1EPCXpj4DbgAnAJyLigWbv5yAxrqeeDtChNuZDbbzgMWdHEftNn5uZWUb8zVgzs8w56M3MMuegHwFJx0haI2lTup0yTNujJH1H0kfb2cdmqzJmSadK+pqkByTdL+l3xqKvo9HoZzskHS7pxlS/XlJX+3vZXBXGfJWkB9M5XSup0me2D2ZVf55F0iWSQlIWH7l00I/MEmBtRMwB1qb1obwPuKstvWqtKmPeByyIiJOBC4APSZrcxj6OSsWf7VgE7IqIE4GlwNh9nakJKo75XqA7In4JuAn4m/b2srmq/jyLpEnAm4D17e1h6zjoR2Ye0JOWe4CL6zWS9MvAccCX2tSvVmo45oj4VkRsSsvbgJ1AZ9t6OHpVfrajfBxuAs6TVO/LgeNFwzFHxB0RsS+trqP4Tsx4VvXnWd5H8aT2ZDs710oO+pE5LiK2A6TbabUNJB0GfBB4e5v71ioNx1wm6QxgIvBQG/rWLPV+tmPGUG0i4ilgD3BsW3rXGlXGXLYI+PeW9qj1Go5Z0mnArIi4pZ0da7VW/ATCuCbpy8Cz61S9u+Im3gDcGhFbx8sFXxPGPLid6cD1wMKI+Ekz+tYmVX62o9JPe4wjlccj6feAbuDslvao9YYdc7pIWwpc3q4OtYuDvkZEnD9UnaQdkqZHxPYUajvrNDsLeLGkNwDPAiZK2hsRB+3v8jdhzEg6CvgCcHVErGtRV1ulys92DLbpl9QBHA083p7utUSlnyqRdD7FE/7ZEfHDNvWtVRqNeRLwi8Cd6SLt2cBqSa+MiN629bIFPHUzMquBhWl5IbCqtkFEXBYRsyOiC3gbsOJgDvkKGo45/dTFzRRj/Uwb+9YsVX62o3wcLgFuj/H9bcOGY07TGP8IvDIi6j7BjzPDjjki9kTE1IjoSv+/6yjGPq5DHhz0I3UN8DJJm4CXpXUkdUv6+Jj2rHWqjPlVwEuAyyXdl/5OHZvujlyacx/82Y6NwMqIeEDSn0t6ZWq2HDhWUh9wFcN/4uqgV3HM76d4VfqZdE7H9W9WVRxzlvwTCGZmmfMVvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXu/wGMwXOa1cZj7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1f82b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "c_var = ['full', 'tied', 'diag', 'spherical']\n",
    "n_components=1\n",
    "models = [BayesianGaussianMixture(n_components, covariance_type=c, init_params='random').fit(predicted_unseen_class_lsa)\n",
    "          for c in c_var]\n",
    "\n",
    "for m in range(len(models)):\n",
    "    plt.title(\"Model with Covariance type: \" + str(c_var[m]))\n",
    "    plt.hist(models[m].predict(predicted_unseen_class_lsa))\n",
    "    pred_ls = models[m].predict(predicted_unseen_class_lsa)\n",
    "    print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(pred_ls, orig_test_labels[pred_class_indices]))\n",
    "    plt.show()\n",
    "#gmm2_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite Dirichlet Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGMM_fits(input_data=lsa_result, cv_type='full', max_comp=21):\n",
    "    mod = BayesianGaussianMixture(n_components=max_comp, covariance_type='full', \n",
    "                                  weight_concentration_prior_type=\"dirichlet_process\", \n",
    "                                  reg_covar=0, init_params='random',\n",
    "        max_iter=1500, mean_precision_prior=.8,random_state=0)\n",
    "    X = np.array(input_data)\n",
    "    mod.fit(X)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_class = 5\n",
    "num_unseen_class =2\n",
    "best_lsa_model = BGMM_fits(input_data=lsa_result, max_comp=num_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IDP Model Parameters based on BIC <bound method BayesianGaussianMixture.get_params of BayesianGaussianMixture(covariance_prior=None, covariance_type='full',\n",
      "            degrees_of_freedom_prior=None, init_params='random',\n",
      "            max_iter=1500, mean_precision_prior=0.8, mean_prior=None,\n",
      "            n_components=5, n_init=1, random_state=0, reg_covar=0,\n",
      "            tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
      "            weight_concentration_prior=None,\n",
      "            weight_concentration_prior_type='dirichlet_process')>\n"
     ]
    }
   ],
   "source": [
    "print \"Best IDP Model Parameters based on BIC\", best_lsa_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.069\n",
      "Completeness: 0.074\n",
      "V-measure: 0.071\n",
      "Adjusted Rand-Index: 0.065\n",
      "Silhouette Coefficient: 0.059\n",
      "fowlkes_mallows_score: 0.267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 127.,    0.,  778.,    0.,    0.,  695.,    0.,  815.,    0.,  688.]),\n",
       " array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1dc3a350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_cluster = best_lsa_model.predict(lsa_result)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df['label'], predicted_cluster))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df['label'], predicted_cluster))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df['label'], predicted_cluster))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df['label'], predicted_cluster))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_result, predicted_cluster, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df['label'], predicted_cluster))\n",
    "plt.hist(predicted_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_comp(predicted_labels,actual_labels):\n",
    "    Cluster_ids = {}\n",
    "    for i in predicted_labels:\n",
    "        Cluster_ids[i] = (predicted_labels==i).nonzero()[0]\n",
    "\n",
    "    targets = np.array(actual_labels)\n",
    "    #print Cluster_ids\n",
    "    for label in Cluster_ids.keys():\n",
    "        #print type(label)\n",
    "        idx = Cluster_ids[label]\n",
    "        print \"Cluster Number\", str(label), \"Composition\", np.bincount(targets[idx])\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_val_labels = best_lsa_model.predict_proba(lsa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+000   0.00000000e+000   3.51689396e-144   1.00000000e+000\n",
      "    8.30675887e-053]\n",
      " [  0.00000000e+000   0.00000000e+000   9.86993622e-002   9.01106994e-001\n",
      "    1.93644262e-004]\n",
      " [  2.03265370e-239   3.45590933e-156   7.12975324e-001   2.86787668e-001\n",
      "    2.37007690e-004]\n",
      " ..., \n",
      " [  0.00000000e+000   0.00000000e+000   8.45298941e-001   1.54701043e-001\n",
      "    1.60401914e-008]\n",
      " [  1.00000000e+000   4.71206321e-016   1.07706479e-037   3.53519379e-041\n",
      "    3.12752230e-034]\n",
      " [  0.00000000e+000   2.46966340e-261   6.40950919e-008   9.98421723e-001\n",
      "    1.57821320e-003]]\n",
      "[  1.00000000e+00   1.82968508e-08   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+00]\n",
      "[[  0.00000000e+000   0.00000000e+000   3.51689396e-144   1.00000000e+000\n",
      "    8.30675887e-053]\n",
      " [  0.00000000e+000   0.00000000e+000   9.86993622e-002   9.01106994e-001\n",
      "    1.93644262e-004]\n",
      " [  2.03265370e-239   1.88880007e-148   7.12975324e-001   2.86787668e-001\n",
      "    2.37007690e-004]\n",
      " ..., \n",
      " [  0.00000000e+000   0.00000000e+000   8.45298941e-001   1.54701043e-001\n",
      "    1.60401914e-008]\n",
      " [  1.00000000e+000   2.57534111e-008   1.07706479e-037   3.53519379e-041\n",
      "    3.12752230e-034]\n",
      " [  0.00000000e+000   1.34977512e-253   6.40950919e-008   9.98421723e-001\n",
      "    1.57821320e-003]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_val_labels\n",
    "val_gmm_class_max_prob_lists = np.array([max(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_class_min_prob_lists = np.array([min(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_delta = val_gmm_class_max_prob_lists - val_gmm_class_min_prob_lists\n",
    "\n",
    "print val_gmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_bgmm_val_class_probs = np.divide(pred_proba_val_labels,val_gmm_delta)\n",
    "print scaled_bgmm_val_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1debdf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_val_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.86428615e-271   2.12970984e-113   1.91396045e-001   1.00000000e+000\n",
      "   9.90671861e-001]\n",
      "[[  0.00000000e+000   0.00000000e+000   3.51689396e-144   1.00000000e+000\n",
      "    8.30675887e-053]\n",
      " [  0.00000000e+000   0.00000000e+000   9.86993622e-002   9.01106994e-001\n",
      "    1.93644262e-004]\n",
      " [  2.03265370e-239   1.88880007e-148   7.12975324e-001   2.86787668e-001\n",
      "    2.37007690e-004]\n",
      " ..., \n",
      " [  0.00000000e+000   0.00000000e+000   8.45298941e-001   1.54701043e-001\n",
      "    1.60401914e-008]\n",
      " [  1.00000000e+000   2.57534111e-008   1.07706479e-037   3.53519379e-041\n",
      "    3.12752230e-034]\n",
      " [  0.00000000e+000   1.34977512e-253   6.40950919e-008   9.98421723e-001\n",
      "    1.57821320e-003]]\n",
      "[[0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " ..., \n",
      " [0 0 1 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[ 0  1  3  4  5  6  7  8 10 11]\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 85.0\n",
    "val_bgmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_bgmm_val_class_probs[:,val], class_threshold) \n",
    "                                     for val in range(len(scaled_bgmm_val_class_probs[0]))])\n",
    "\n",
    "print val_bgmm_class_prob_percentile_cutoff\n",
    "\n",
    "bgmm_val_class_preds = np.greater_equal(scaled_bgmm_val_class_probs,val_bgmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "print scaled_bgmm_val_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "val_bgmm_valid_class_probs = np.multiply(scaled_bgmm_val_class_probs, bgmm_val_class_preds)\n",
    "val_bgmm_valid_class = np.greater_equal(np.ceil(val_bgmm_valid_class_probs),1).astype(int)\n",
    "print val_bgmm_valid_class\n",
    "val_bgmm_predicted_multinomial = np.multiply(val_bgmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(val_bgmm_predicted_multinomial, axis=1))\n",
    "bgmm_predicted_val_class = np.max(val_bgmm_predicted_multinomial,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487 153   0 151 168   0 134 146] [864  75   0  75  75   0  75  75]\n",
      "1239 1239\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(valid_final_labels), np.bincount(gmm_predicted_val_class)\n",
    "print np.sum(np.bincount(valid_final_labels)), np.sum(np.bincount(gmm_predicted_val_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Unseen Class Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composition of bgmm_predicted_valid_class for true unseen class indices [177  31   0  46  90   0  86  57]\n",
      "487\n"
     ]
    }
   ],
   "source": [
    "print \"Composition of bgmm_predicted_valid_class for true unseen class indices\", np.bincount(sorted(bgmm_predicted_val_class[missing_class_idx_val]))\n",
    "print sum(np.bincount(sorted(gmm_predicted_val_class[missing_class_idx_val])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.35      0.35       513\n",
      "          1       0.07      0.14      0.10        76\n",
      "          3       0.05      0.09      0.07        92\n",
      "          4       0.16      0.15      0.15       186\n",
      "          6       0.11      0.08      0.09       186\n",
      "          7       0.12      0.10      0.11       186\n",
      "\n",
      "avg / total       0.22      0.21      0.21      1239\n",
      "\n",
      "[[177  72  67  77  63  57]\n",
      " [ 31  11   4  13   7  10]\n",
      " [ 46  10   8  13   7   8]\n",
      " [ 90  11   9  27  16  33]\n",
      " [ 86  24  25  16  15  20]\n",
      " [ 57  25  38  22  26  18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "print classification_report(bgmm_predicted_val_class, valid_final_labels)\n",
    "print confusion_matrix(bgmm_predicted_val_class, valid_final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.345029239766 0.363449691992 0.354\n"
     ]
    }
   ],
   "source": [
    "def calculate_unseen_class_f1score(pred_class, true_class, unseen_class_id):\n",
    "    predicted_zero_ind = (pred_class==unseen_class_id).nonzero()[0]\n",
    "    predicted_nonzero_ind = (pred_class >unseen_class_id).nonzero()[0]\n",
    "    #print np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    TP = np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    FP =  sum(np.bincount(true_class[predicted_zero_ind])) - TP\n",
    "    FN =  np.bincount(true_class[predicted_nonzero_ind])[0]\n",
    "    #print TP, FP, FN\n",
    "    unseen_class_precision = float(TP)/(TP+FP)\n",
    "    unseen_class_recall = float(TP)/(TP+FN)\n",
    "    unseen_class_f1 = 2*unseen_class_precision*unseen_class_recall/(unseen_class_precision+unseen_class_recall)\n",
    "    #print unseen_class_precision,unseen_class_recall,unseen_class_f1\n",
    "    return unseen_class_precision, unseen_class_recall,unseen_class_f1\n",
    "    \n",
    "pr,re,f1 = calculate_unseen_class_f1score(bgmm_predicted_val_class,valid_final_labels,0)\n",
    "print pr,re,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  58 F1 Score:  0.00811359026369\n",
      "Actual Unseen Class 487 Predicted Unseen Class 6\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  59 F1 Score:  0.0120240480962\n",
      "Actual Unseen Class 487 Predicted Unseen Class 12\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  60 F1 Score:  0.0235756385069\n",
      "Actual Unseen Class 487 Predicted Unseen Class 22\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  61 F1 Score:  0.0308285163776\n",
      "Actual Unseen Class 487 Predicted Unseen Class 32\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  62 F1 Score:  0.0379506641366\n",
      "Actual Unseen Class 487 Predicted Unseen Class 40\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  63 F1 Score:  0.0410447761194\n",
      "Actual Unseen Class 487 Predicted Unseen Class 49\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  64 F1 Score:  0.051376146789\n",
      "Actual Unseen Class 487 Predicted Unseen Class 58\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  65 F1 Score:  0.0580762250454\n",
      "Actual Unseen Class 487 Predicted Unseen Class 64\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  66 F1 Score:  0.0819964349376\n",
      "Actual Unseen Class 487 Predicted Unseen Class 74\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  67 F1 Score:  0.0909090909091\n",
      "Actual Unseen Class 487 Predicted Unseen Class 85\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  68 F1 Score:  0.106529209622\n",
      "Actual Unseen Class 487 Predicted Unseen Class 95\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  69 F1 Score:  0.13\n",
      "Actual Unseen Class 487 Predicted Unseen Class 113\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  70 F1 Score:  0.145395799677\n",
      "Actual Unseen Class 487 Predicted Unseen Class 132\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  71 F1 Score:  0.163265306122\n",
      "Actual Unseen Class 487 Predicted Unseen Class 150\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  72 F1 Score:  0.176024279211\n",
      "Actual Unseen Class 487 Predicted Unseen Class 172\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  73 F1 Score:  0.190895741557\n",
      "Actual Unseen Class 487 Predicted Unseen Class 194\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  74 F1 Score:  0.206896551724\n",
      "Actual Unseen Class 487 Predicted Unseen Class 209\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  75 F1 Score:  0.212290502793\n",
      "Actual Unseen Class 487 Predicted Unseen Class 229\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  76 F1 Score:  0.225237449118\n",
      "Actual Unseen Class 487 Predicted Unseen Class 250\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  77 F1 Score:  0.248366013072\n",
      "Actual Unseen Class 487 Predicted Unseen Class 278\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  78 F1 Score:  0.264631043257\n",
      "Actual Unseen Class 487 Predicted Unseen Class 299\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  79 F1 Score:  0.281829419036\n",
      "Actual Unseen Class 487 Predicted Unseen Class 322\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  80 F1 Score:  0.289127837515\n",
      "Actual Unseen Class 487 Predicted Unseen Class 350\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  81 F1 Score:  0.298611111111\n",
      "Actual Unseen Class 487 Predicted Unseen Class 377\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  82 F1 Score:  0.302013422819\n",
      "Actual Unseen Class 487 Predicted Unseen Class 407\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  83 F1 Score:  0.324324324324\n",
      "Actual Unseen Class 487 Predicted Unseen Class 438\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  84 F1 Score:  0.337851929093\n",
      "Actual Unseen Class 487 Predicted Unseen Class 472\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  85 F1 Score:  0.354\n",
      "Actual Unseen Class 487 Predicted Unseen Class 513\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  86 F1 Score:  0.377906976744\n",
      "Actual Unseen Class 487 Predicted Unseen Class 545\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  87 F1 Score:  0.388422035481\n",
      "Actual Unseen Class 487 Predicted Unseen Class 584\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  88 F1 Score:  0.39566395664\n",
      "Actual Unseen Class 487 Predicted Unseen Class 620\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  89 F1 Score:  0.40350877193\n",
      "Actual Unseen Class 487 Predicted Unseen Class 653\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  90 F1 Score:  0.412213740458\n",
      "Actual Unseen Class 487 Predicted Unseen Class 692\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  91 F1 Score:  0.427040395713\n",
      "Actual Unseen Class 487 Predicted Unseen Class 726\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  92 F1 Score:  0.441223832528\n",
      "Actual Unseen Class 487 Predicted Unseen Class 755\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  93 F1 Score:  0.456031128405\n",
      "Actual Unseen Class 487 Predicted Unseen Class 798\n",
      "[0 1 3 4 6 7] [0 1 3 4 6 7]\n",
      "Threshold:  94 F1 Score:  0.465608465608\n",
      "Actual Unseen Class 487 Predicted Unseen Class 836\n",
      "Best Threshold:  85\n",
      "Best F1 Score:  0.354\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 0.0\n",
    "best_f1_score=0.0\n",
    "for threshold in range(50,95):\n",
    "    try:\n",
    "        val_bgmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_bgmm_val_class_probs[:,val], float(threshold)) \n",
    "                                             for val in range(len(scaled_bgmm_val_class_probs[0]))])\n",
    "\n",
    "        #print val_gmm_class_prob_percentile_cutoff\n",
    "\n",
    "        bgmm_val_class_preds = np.greater_equal(scaled_bgmm_val_class_probs,val_bgmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "        #print scaled_gmm_val_class_probs\n",
    "        # Predict the test label based on percental\n",
    "        # If a data is below 80% for prob of all class, it belongs to open class\n",
    "        val_bgmm_valid_class_probs_dup = np.multiply(scaled_bgmm_val_class_probs, bgmm_val_class_preds)\n",
    "\n",
    "        val_bgmm_valid_class_max_probs = np.max(val_bgmm_valid_class_probs_dup, axis=1)\n",
    "        #print gmm_valid_class_max_probs\n",
    "        #print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "        val_temp = np.equal(val_bgmm_valid_class_probs_dup , val_bgmm_valid_class_max_probs.reshape(len(val_bgmm_valid_class_max_probs),1))\n",
    "        val_bgmm_valid_class_probs=np.multiply(val_bgmm_valid_class_probs_dup,val_temp)\n",
    "        val_bgmm_valid_class = np.greater_equal(np.ceil(val_bgmm_valid_class_probs),1).astype(int)\n",
    "        #print val_gmm_valid_class\n",
    "        val_bgmm_predicted_multinomial = np.multiply(val_bgmm_valid_class, np.unique(train_final_labels))\n",
    "        #print np.unique(np.sum(val_gmm_predicted_multinomial, axis=1))\n",
    "        bgmm_predicted_val_class = np.max(val_bgmm_predicted_multinomial,axis=1)  \n",
    "        print np.unique(bgmm_predicted_val_class), np.unique(valid_final_labels)\n",
    "        pr,re,f1 = calculate_unseen_class_f1score(bgmm_predicted_val_class,valid_final_labels,0)\n",
    "        print \"Threshold: \",threshold, \"F1 Score: \", f1 \n",
    "        print \"Actual Unseen Class\", np.bincount(valid_final_labels)[0], \"Predicted Unseen Class\",np.bincount(bgmm_predicted_val_class)[0]\n",
    "        # Set the threshold so that not unseen class volume is actual unseen class volume in validation set\n",
    "        unseen_class_ratio = float(np.bincount(bgmm_predicted_val_class)[0])/np.bincount(valid_final_labels)[0]\n",
    "        #overall_F1_score = f1_score(gmm_predicted_val_class, valid_final_labels)\n",
    "        if f1 > best_f1_score and unseen_class_ratio < 1.1:\n",
    "\n",
    "            best_f1_score = f1\n",
    "            best_threshold = threshold\n",
    "    except:\n",
    "        print \"Threshold Too Low. No unseen class prediction\"\n",
    "        \n",
    "print \"Best Threshold: \", best_threshold\n",
    "print \"Best F1 Score: \", best_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test_labels = best_lsa_model.predict_proba(lsa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+000   0.00000000e+000   2.09445727e-078   1.00000000e+000\n",
      "    3.12510209e-035]\n",
      " [  0.00000000e+000   0.00000000e+000   4.29714554e-138   1.00000000e+000\n",
      "    7.42276162e-053]\n",
      " [  0.00000000e+000   3.04180292e-130   1.79115697e-017   3.67791630e-016\n",
      "    1.00000000e+000]\n",
      " ..., \n",
      " [  0.00000000e+000   0.00000000e+000   1.13983631e-029   1.00000000e+000\n",
      "    2.73095555e-012]\n",
      " [  1.00000000e+000   4.71206321e-016   1.07706479e-037   3.53519379e-041\n",
      "    3.12752230e-034]\n",
      " [  0.00000000e+000   0.00000000e+000   1.35039751e-094   1.00000000e+000\n",
      "    2.16355363e-029]]\n",
      "[  1.00000000e+00   6.08987076e-12   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+00]\n",
      "[[  0.00000000e+000   0.00000000e+000   2.09445727e-078   1.00000000e+000\n",
      "    3.12510209e-035]\n",
      " [  0.00000000e+000   0.00000000e+000   4.29714554e-138   1.00000000e+000\n",
      "    7.42276162e-053]\n",
      " [  0.00000000e+000   4.99485628e-119   1.79115697e-017   3.67791630e-016\n",
      "    1.00000000e+000]\n",
      " ..., \n",
      " [  0.00000000e+000   0.00000000e+000   1.13983631e-029   1.00000000e+000\n",
      "    2.73095555e-012]\n",
      " [  1.00000000e+000   7.73754222e-005   1.07706479e-037   3.53519379e-041\n",
      "    3.12752230e-034]\n",
      " [  0.00000000e+000   0.00000000e+000   1.35039751e-094   1.00000000e+000\n",
      "    2.16355363e-029]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_test_labels\n",
    "bgmm_class_max_prob_lists = np.array([max(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "bgmm_class_min_prob_lists = np.array([min(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "bgmm_delta = bgmm_class_max_prob_lists - bgmm_class_min_prob_lists\n",
    "\n",
    "print bgmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_bgmm_test_class_probs = np.divide(pred_proba_test_labels,bgmm_delta)\n",
    "print scaled_bgmm_test_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e1f670250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_test_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  1.00000000e+00   7.73754222e-05   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00]]\n",
      "[ 1.  1.  1. ...,  0.  1.  1.]\n",
      "[[0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " ..., \n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]]\n",
      "[0 1 3 4 6 7]\n"
     ]
    }
   ],
   "source": [
    "print best_threshold\n",
    "bgmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_bgmm_test_class_probs[:,val], best_threshold) \n",
    "                                     for val in range(len(scaled_bgmm_test_class_probs[0]))])\n",
    "\n",
    "#print gmm_class_prob_percentile_cutoff\n",
    "\n",
    "bgmm_test_class_preds = np.greater_equal(scaled_bgmm_test_class_probs,bgmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "#print scaled_gmm_test_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "bgmm_valid_class_probs_dup = np.multiply(scaled_bgmm_test_class_probs, bgmm_test_class_preds)\n",
    "print bgmm_valid_class_probs_dup\n",
    "bgmm_valid_class_max_probs = np.max(bgmm_valid_class_probs_dup, axis=1)\n",
    "print bgmm_valid_class_max_probs\n",
    "#print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "temp = np.equal(bgmm_valid_class_probs_dup , bgmm_valid_class_max_probs.reshape(len(bgmm_valid_class_max_probs),1))\n",
    "bgmm_valid_class_probs=np.multiply(bgmm_valid_class_probs_dup,temp)\n",
    "bgmm_valid_class = np.greater_equal(np.ceil(bgmm_valid_class_probs),1).astype(int)\n",
    "print bgmm_valid_class\n",
    "bgmm_predicted_multinomial = np.multiply(bgmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(bgmm_predicted_multinomial, axis=1))\n",
    "bgmm_predicted_test_class = np.max(bgmm_predicted_multinomial,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[593 206   0 187 192   0 160 211] [643 161   0  47 232   0 233 233]\n",
      "1549 1549\n",
      "[[235  65  21 106  94  72]\n",
      " [ 79  26   6  30  29  36]\n",
      " [ 74  12   5   7  36  53]\n",
      " [ 91  16   7  29  22  27]\n",
      " [ 72  18   4  18  20  28]\n",
      " [ 92  24   4  42  32  17]]\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(test_labels), np.bincount(bgmm_predicted_test_class)\n",
    "print np.sum(np.bincount(test_labels)), np.sum(np.bincount(bgmm_predicted_test_class))\n",
    "print confusion_matrix(test_labels, bgmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.37      0.40      0.38       593\n",
      "          1       0.16      0.13      0.14       206\n",
      "          3       0.11      0.03      0.04       187\n",
      "          4       0.12      0.15      0.14       192\n",
      "          6       0.09      0.12      0.10       160\n",
      "          7       0.07      0.08      0.08       211\n",
      "\n",
      "avg / total       0.21      0.21      0.21      1549\n",
      "\n",
      "0.214331826985\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, bgmm_predicted_test_class)\n",
    "print accuracy_score(test_labels, bgmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen Class Precision, Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Class Precision:  0.365474339036\n",
      "Unseen Class Recall:  0.39629005059\n",
      "Unseen Class F1 Score:  0.380258899676\n"
     ]
    }
   ],
   "source": [
    "print \"Unseen Class Precision: \", calculate_unseen_class_f1score(bgmm_predicted_test_class,test_labels,0)[0]\n",
    "print \"Unseen Class Recall: \", calculate_unseen_class_f1score(bgmm_predicted_test_class,test_labels,0)[1]\n",
    "print \"Unseen Class F1 Score: \", calculate_unseen_class_f1score(bgmm_predicted_test_class,test_labels,0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.013\n",
      "Completeness: 0.016\n",
      "V-measure: 0.014\n",
      "Adjusted Rand-Index: 0.009\n",
      "Silhouette Coefficient: 0.030\n",
      "fowlkes_mallows_score: 0.273\n"
     ]
    }
   ],
   "source": [
    "pred_class_indices = (gmm_predicted_test_class==0).nonzero()[0]\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_test, gmm_predicted_test_class, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df_test['label'], gmm_predicted_test_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
